#!/usr/bin/env python3
"""
é…ç½®åŒ¹é…å™¨æ¨¡å—
è´Ÿè´£ä»ä¼˜åŒ–ç»“æœä¸­åŒ¹é…å’ŒåŠ è½½æœ€ä¼˜é…ç½®
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class OptimalConfig:
    """æœ€ä¼˜é…ç½®ç±»"""

    def __init__(self, dataset_name: str, config_data: Dict[str, Any],
                 source_file: str = None, confidence: float = 1.0):
        self.dataset_name = dataset_name
        self.config_data = config_data
        self.source_file = source_file
        self.confidence = confidence  # é…ç½®åŒ¹é…çš„ç½®ä¿¡åº¦
        self.timestamp = self._extract_timestamp()

    def _extract_timestamp(self) -> Optional[datetime]:
        """ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³"""
        if not self.source_file:
            return None

        try:
            # å°è¯•ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³
            timestamp_pattern = r'(\d{8}_\d{6})'
            match = re.search(timestamp_pattern, self.source_file)
            if match:
                timestamp_str = match.group(1)
                return datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
        except:
            pass

        return None

    def get_best_config(self) -> Dict[str, Any]:
        """è·å–æœ€ä½³é…ç½®å‚æ•°"""
        if 'results' in self.config_data and 'best_config' in self.config_data['results']:
            return self.config_data['results']['best_config']
        elif 'best_config' in self.config_data:
            return self.config_data['best_config']
        else:
            return {}

    def get_best_score(self) -> Optional[float]:
        """è·å–æœ€ä½³å¾—åˆ†"""
        if 'results' in self.config_data and 'best_score' in self.config_data['results']:
            return self.config_data['results']['best_score']
        elif 'best_score' in self.config_data:
            return self.config_data['best_score']
        else:
            return None


class ConfigMatcher:
    """é…ç½®åŒ¹é…å™¨"""

    def __init__(self, results_dir: str = "Optimal parameter experiment/results"):
        self.results_dir = Path(results_dir)
        self.configs: Dict[str, List[OptimalConfig]] = {}
        self.dataset_aliases = {
            'ml100k': ['movielens100k', 'm100k', '100k'],
            'movielens100k': ['ml100k', 'm100k', '100k'],
            'netflix': ['nf'],
            'filmtrust': ['flimtrust', 'ft'],
            'flimtrust': ['filmtrust', 'ft'],
            'ciaodvd': ['ciao'],
            'movielens1m': ['ml1m', 'm1m', '1m'],
            'amazon': ['amz']
        }
        self._scan_config_files()

    def _scan_config_files(self):
        """æ‰«æé…ç½®æ–‡ä»¶"""
        if not self.results_dir.exists():
            logger.warning(f"ç»“æœç›®å½•ä¸å­˜åœ¨: {self.results_dir}")
            return

        logger.info(f"æ‰«æé…ç½®ç›®å½•: {self.results_dir}")

        # é€’å½’æœç´¢JSONæ–‡ä»¶
        json_files = list(self.results_dir.rglob("*.json"))

        for json_file in json_files:
            try:
                config = self._parse_config_file(json_file)
                if config:
                    dataset_name = config.dataset_name
                    if dataset_name not in self.configs:
                        self.configs[dataset_name] = []
                    self.configs[dataset_name].append(config)
            except Exception as e:
                logger.warning(f"è§£æé…ç½®æ–‡ä»¶å¤±è´¥ {json_file}: {e}")

        # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        for dataset_configs in self.configs.values():
            dataset_configs.sort(key=lambda x: x.timestamp or datetime.min, reverse=True)

        logger.info(f"åŠ è½½äº† {sum(len(configs) for configs in self.configs.values())} ä¸ªé…ç½®æ–‡ä»¶")

    def _parse_config_file(self, json_file: Path) -> Optional[OptimalConfig]:
        """è§£æé…ç½®æ–‡ä»¶"""
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # è¯†åˆ«æ•°æ®é›†åç§°
            dataset_name = self._identify_dataset_from_file(json_file, data)
            if not dataset_name:
                return None

            # éªŒè¯é…ç½®å®Œæ•´æ€§
            if not self._validate_config_data(data):
                logger.warning(f"é…ç½®æ–‡ä»¶æ ¼å¼ä¸å®Œæ•´: {json_file}")
                return None

            return OptimalConfig(
                dataset_name=dataset_name,
                config_data=data,
                source_file=str(json_file),
                confidence=1.0
            )

        except json.JSONDecodeError as e:
            logger.error(f"JSONæ ¼å¼é”™è¯¯ {json_file}: {e}")
            return None
        except Exception as e:
            logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥ {json_file}: {e}")
            return None

    def _identify_dataset_from_file(self, json_file: Path, data: Dict) -> Optional[str]:
        """ä»æ–‡ä»¶è·¯å¾„å’Œå†…å®¹è¯†åˆ«æ•°æ®é›†åç§°"""
        # 1. ä»æ–‡ä»¶è·¯å¾„è¯†åˆ«
        path_parts = json_file.parts
        for part in path_parts:
            part_lower = part.lower()
            for dataset_name, aliases in self.dataset_aliases.items():
                if (dataset_name in part_lower or
                    any(alias in part_lower for alias in aliases)):
                    return dataset_name

        # 2. ä»æ–‡ä»¶åè¯†åˆ«
        filename = json_file.stem.lower()
        for dataset_name, aliases in self.dataset_aliases.items():
            if (dataset_name in filename or
                any(alias in filename for alias in aliases)):
                return dataset_name

        # 3. ä»é…ç½®å†…å®¹è¯†åˆ«
        if 'dataset_info' in data:
            dataset_info = data['dataset_info']
            if 'dataset_name' in dataset_info:
                return dataset_info['dataset_name'].lower()
            if 'dataset_file' in dataset_info:
                file_path = dataset_info['dataset_file'].lower()
                for dataset_name, aliases in self.dataset_aliases.items():
                    if (dataset_name in file_path or
                        any(alias in file_path for alias in aliases)):
                        return dataset_name

        # 4. ä»å®éªŒä¿¡æ¯è¯†åˆ«
        if 'experiment_info' in data:
            exp_info = data['experiment_info']
            if 'dataset' in exp_info:
                return exp_info['dataset'].lower()

        return None

    def _validate_config_data(self, data: Dict) -> bool:
        """éªŒè¯é…ç½®æ•°æ®å®Œæ•´æ€§"""
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ä½³é…ç½®
        has_best_config = (
            ('results' in data and 'best_config' in data['results']) or
            'best_config' in data
        )

        if not has_best_config:
            return False

        # æ£€æŸ¥æœ€ä½³é…ç½®çš„å…³é”®å‚æ•°
        best_config = data.get('results', {}).get('best_config') or data.get('best_config', {})
        required_params = ['learning_rate', 'latent_factors', 'lambda_reg']

        return all(param in best_config for param in required_params)

    def find_config(self, dataset_name: str) -> Optional[OptimalConfig]:
        """æŸ¥æ‰¾æ•°æ®é›†çš„æœ€ä¼˜é…ç½®"""
        dataset_name_lower = dataset_name.lower()

        # 1. ç²¾ç¡®åŒ¹é…
        if dataset_name_lower in self.configs:
            return self.configs[dataset_name_lower][0]  # è¿”å›æœ€æ–°çš„é…ç½®

        # 2. åˆ«ååŒ¹é…
        for stored_name, aliases in self.dataset_aliases.items():
            if dataset_name_lower in aliases and stored_name in self.configs:
                return self.configs[stored_name][0]

        # 3. æ¨¡ç³ŠåŒ¹é…
        for stored_name in self.configs.keys():
            if (dataset_name_lower in stored_name or
                stored_name in dataset_name_lower):
                logger.info(f"é€šè¿‡æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°é…ç½®: {dataset_name} -> {stored_name}")
                config = self.configs[stored_name][0]
                config.confidence = 0.8  # é™ä½ç½®ä¿¡åº¦
                return config

        return None

    def get_similar_config(self, dataset_name: str) -> Optional[OptimalConfig]:
        """è·å–ç›¸ä¼¼æ•°æ®é›†çš„é…ç½®"""
        # å®šä¹‰æ•°æ®é›†ç›¸ä¼¼æ€§
        similarity_groups = [
            ['ml100k', 'movielens100k', 'movielens1m'],  # MovieLensç³»åˆ—
            ['filmtrust', 'flimtrust', 'ciaodvd'],       # ç”µå½±è¯„åˆ†ç³»åˆ—
            ['netflix', 'amazon', 'epinions']            # å¤§å‹è¯„åˆ†ç³»åˆ—
        ]

        dataset_name_lower = dataset_name.lower()

        # æŸ¥æ‰¾ç›¸ä¼¼ç»„
        for group in similarity_groups:
            if any(name in dataset_name_lower for name in group):
                # åœ¨åŒç»„ä¸­æŸ¥æ‰¾å¯ç”¨é…ç½®
                for similar_name in group:
                    if similar_name in self.configs:
                        logger.info(f"ä½¿ç”¨ç›¸ä¼¼æ•°æ®é›†é…ç½®: {dataset_name} -> {similar_name}")
                        config = self.configs[similar_name][0]
                        config.confidence = 0.6  # è¿›ä¸€æ­¥é™ä½ç½®ä¿¡åº¦
                        return config

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼çš„ï¼Œè¿”å›ä»»æ„ä¸€ä¸ªé…ç½®
        if self.configs:
            logger.info(f"ä½¿ç”¨é»˜è®¤é…ç½®: {dataset_name}")
            first_config = next(iter(self.configs.values()))[0]
            first_config.confidence = 0.3  # æœ€ä½ç½®ä¿¡åº¦
            return first_config

        return None

    def build_model_configs(self, optimal_config: OptimalConfig) -> List[Dict[str, Any]]:
        """åŸºäºæœ€ä¼˜é…ç½®æ„å»ºä¸åŒæŸå¤±å‡½æ•°çš„æ¨¡å‹é…ç½®"""
        base_config = optimal_config.get_best_config()

        # æå–åŸºç¡€å‚æ•°
        base_params = {
            'n_factors': base_config.get('latent_factors', 50),
            'learning_rate': base_config.get('learning_rate', 0.01),
            'n_epochs': 100,  # å¯ä»¥ä»é…ç½®ä¸­è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
            'use_bias': True,
            'regularizer': {
                'type': 'L2',
                'lambda_reg': base_config.get('lambda_reg', 0.01)
            },
            'initializer': {'type': 'Normal', 'mean': 0.0, 'std': 0.01}
        }

        # æ„å»ºä¸åŒæŸå¤±å‡½æ•°çš„é…ç½®
        model_configs = []

        # 1. HPLä¼˜åŒ–æ¨¡å‹
        hpl_config = base_params.copy()
        hpl_config.update({
            'name': 'HPL_optimized',
            'description': 'ä¼˜åŒ–åçš„HPLæŸå¤±å‡½æ•°æ¨¡å‹',
            'loss_function': {
                'type': 'HPL',
                'delta1': base_config.get('delta1', 0.5),
                'delta2': base_config.get('delta2', 2.0),
                'l_max': base_config.get('l_max', 3.0)
            }
        })
        model_configs.append(hpl_config)

        # 2. L2åŸºçº¿æ¨¡å‹
        l2_config = base_params.copy()
        l2_config.update({
            'name': 'L2_baseline',
            'description': 'L2æŸå¤±å‡½æ•°åŸºçº¿æ¨¡å‹',
            'loss_function': {'type': 'L2'}
        })
        model_configs.append(l2_config)

        # 3. L1åŸºçº¿æ¨¡å‹
        l1_config = base_params.copy()
        l1_config.update({
            'name': 'L1_baseline',
            'description': 'L1æŸå¤±å‡½æ•°åŸºçº¿æ¨¡å‹',
            'loss_function': {'type': 'L1'}
        })
        model_configs.append(l1_config)

        # 4. HuberæŸå¤±æ¨¡å‹
        huber_config = base_params.copy()
        huber_config.update({
            'name': 'Huber_robust',
            'description': 'HuberæŸå¤±å‡½æ•°é²æ£’æ¨¡å‹',
            'loss_function': {'type': 'Huber', 'delta': 1.0}
        })
        model_configs.append(huber_config)

        # 5. LogcoshæŸå¤±æ¨¡å‹
        logcosh_config = base_params.copy()
        logcosh_config.update({
            'name': 'Logcosh_robust',
            'description': 'LogcoshæŸå¤±å‡½æ•°é²æ£’æ¨¡å‹',
            'loss_function': {'type': 'Logcosh'}
        })
        model_configs.append(logcosh_config)

        # 6. SigmoidLikeæŸå¤±æ¨¡å‹
        sigmoid_config = base_params.copy()
        sigmoid_config.update({
            'name': 'Sigmoid_robust',
            'description': 'Sigmoidç±»æŸå¤±å‡½æ•°æ¨¡å‹',
            'loss_function': {
                'type': 'SigmoidLike',
                'alpha': 1.0,
                'l_max': base_config.get('l_max', 3.0)
            }
        })
        model_configs.append(sigmoid_config)

        return model_configs

    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'learning_rate': 0.01,
            'latent_factors': 50,
            'lambda_reg': 0.01,
            'delta1': 0.5,
            'delta2': 2.0,
            'l_max': 3.0
        }

    def list_available_configs(self) -> Dict[str, List[str]]:
        """åˆ—å‡ºå¯ç”¨çš„é…ç½®"""
        result = {}
        for dataset_name, configs in self.configs.items():
            result[dataset_name] = [
                f"{config.source_file} (confidence: {config.confidence:.2f})"
                for config in configs
            ]
        return result

    def print_config_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("\n" + "="*80)
        print("ğŸ“‹ å¯ç”¨é…ç½®æ‘˜è¦")
        print("="*80)

        if not self.configs:
            print("âŒ æœªå‘ç°ä»»ä½•é…ç½®æ–‡ä»¶")
            return

        for dataset_name, configs in self.configs.items():
            print(f"\nğŸ“Š {dataset_name.upper()}:")
            for i, config in enumerate(configs, 1):
                best_score = config.get_best_score()
                timestamp = config.timestamp.strftime('%Y-%m-%d %H:%M') if config.timestamp else 'Unknown'
                # ä¿®å¤æ ¼å¼åŒ–é—®é¢˜
                score_str = f"{best_score:.4f}" if best_score is not None else 'N/A'
                print(f"  [{i}] å¾—åˆ†: {score_str} | "
                      f"æ—¶é—´: {timestamp} | ç½®ä¿¡åº¦: {config.confidence:.2f}")
                print(f"      æ–‡ä»¶: {Path(config.source_file).name if config.source_file else 'N/A'}")

        print("="*80)

    def print_model_configs(self, model_configs: List[Dict[str, Any]]):
        """æ‰“å°æ¨¡å‹é…ç½®ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ”§ ç”Ÿæˆçš„æ¨¡å‹é…ç½®è¯¦æƒ…")
        print("="*80)

        for i, config in enumerate(model_configs, 1):
            print(f"\nã€æ¨¡å‹ {i}ã€‘{config['name']}")
            print(f"æè¿°: {config['description']}")
            print("-" * 60)

            # åŸºç¡€å‚æ•°
            print("ğŸ“Š åŸºç¡€å‚æ•°:")
            print(f"  â€¢ æ½œåœ¨å› å­æ•°é‡: {config['n_factors']}")
            print(f"  â€¢ å­¦ä¹ ç‡: {config['learning_rate']}")
            print(f"  â€¢ è®­ç»ƒè½®æ•°: {config['n_epochs']}")
            print(f"  â€¢ ä½¿ç”¨åç½®: {config['use_bias']}")

            # æŸå¤±å‡½æ•°å‚æ•°
            print("ğŸ¯ æŸå¤±å‡½æ•°:")
            loss_func = config['loss_function']
            print(f"  â€¢ ç±»å‹: {loss_func['type']}")

            if loss_func['type'] == 'HPL':
                print(f"  â€¢ Delta1: {loss_func['delta1']}")
                print(f"  â€¢ Delta2: {loss_func['delta2']}")
                print(f"  â€¢ L_max: {loss_func['l_max']}")
            elif loss_func['type'] == 'Huber':
                print(f"  â€¢ Delta: {loss_func['delta']}")
            elif loss_func['type'] == 'SigmoidLike':
                print(f"  â€¢ Alpha: {loss_func['alpha']}")
                print(f"  â€¢ L_max: {loss_func['l_max']}")

            # æ­£åˆ™åŒ–å‚æ•°
            print("ğŸ›¡ï¸ æ­£åˆ™åŒ–:")
            reg = config['regularizer']
            print(f"  â€¢ ç±»å‹: {reg['type']}")
            print(f"  â€¢ Lambda: {reg['lambda_reg']}")

            # åˆå§‹åŒ–å‚æ•°
            print("ğŸ² åˆå§‹åŒ–:")
            init = config['initializer']
            print(f"  â€¢ ç±»å‹: {init['type']}")
            print(f"  â€¢ å‡å€¼: {init['mean']}")
            print(f"  â€¢ æ ‡å‡†å·®: {init['std']}")

        print("="*80)

def main():
    """æµ‹è¯•å‡½æ•°"""
    matcher = ConfigMatcher()
    matcher.print_config_summary()

    # æµ‹è¯•é…ç½®æŸ¥æ‰¾
    test_datasets = ['ml100k', 'netflix', 'filmtrust']
    for dataset in test_datasets:
        print(f"\nğŸ” æŸ¥æ‰¾ {dataset} çš„é…ç½®:")
        config = matcher.find_config(dataset)
        if config:
            print(f"  âœ… æ‰¾åˆ°é…ç½® (ç½®ä¿¡åº¦: {config.confidence:.2f})")

            # ç”Ÿæˆæ¨¡å‹é…ç½®
            model_configs = matcher.build_model_configs(config)
            print(f"  ğŸ“‹ ç”Ÿæˆäº† {len(model_configs)} ä¸ªæ¨¡å‹é…ç½®")

            # æ‰“å°è¯¦ç»†çš„æ¨¡å‹é…ç½®ä¿¡æ¯
            matcher.print_model_configs(model_configs)

            # æ‰“å°æœ€ä¼˜é…ç½®çš„åŸå§‹å‚æ•°
            print(f"\nğŸ“ˆ {dataset} çš„æœ€ä¼˜å‚æ•°:")
            best_config = config.get_best_config()
            for key, value in best_config.items():
                print(f"  â€¢ {key}: {value}")

            best_score = config.get_best_score()
            if best_score:
                print(f"  â€¢ æœ€ä½³å¾—åˆ†: {best_score:.4f}")

        else:
            print(f"  âŒ æœªæ‰¾åˆ°é…ç½®ï¼Œå°è¯•ç›¸ä¼¼é…ç½®...")
            similar_config = matcher.get_similar_config(dataset)
            if similar_config:
                print(f"  ğŸ”„ ä½¿ç”¨ç›¸ä¼¼é…ç½® (ç½®ä¿¡åº¦: {similar_config.confidence:.2f})")
                model_configs = matcher.build_model_configs(similar_config)
                matcher.print_model_configs(model_configs)
            else:
                print(f"  âŒ æ— å¯ç”¨é…ç½®")


if __name__ == "__main__":
    main()


