#!/usr/bin/env python3
"""
æ•°æ®é›†é€‰æ‹©å™¨æ¨¡å—
è´Ÿè´£æ‰«æã€å±•ç¤ºå’Œé€‰æ‹©å¯ç”¨çš„æ•°æ®é›†
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class DatasetInfo:
    """æ•°æ®é›†ä¿¡æ¯ç±»"""

    def __init__(self, name: str, file_path: str, display_name: str = None):
        self.name = name
        self.file_path = file_path
        self.display_name = display_name or name
        self.file_size = self._get_file_size()
        self.estimated_records = self._estimate_records()

    def _get_file_size(self) -> str:
        """è·å–æ–‡ä»¶å¤§å°"""
        try:
            size_bytes = os.path.getsize(self.file_path)
            if size_bytes < 1024:
                return f"{size_bytes} B"
            elif size_bytes < 1024 * 1024:
                return f"{size_bytes / 1024:.1f} KB"
            elif size_bytes < 1024 * 1024 * 1024:
                return f"{size_bytes / (1024 * 1024):.1f} MB"
            else:
                return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"
        except:
            return "Unknown"

    def _estimate_records(self) -> str:
        """ä¼°ç®—è®°å½•æ•°é‡"""
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                # è¯»å–å‰å‡ è¡Œä¼°ç®—
                lines = 0
                for _ in range(1000):
                    if f.readline():
                        lines += 1
                    else:
                        break

                if lines < 1000:
                    return f"~{lines}"
                else:
                    # ä¼°ç®—æ€»è¡Œæ•°
                    f.seek(0, 2)  # ç§»åˆ°æ–‡ä»¶æœ«å°¾
                    file_size = f.tell()
                    f.seek(0)
                    avg_line_size = f.tell() / lines if lines > 0 else 100
                    estimated_lines = int(file_size / avg_line_size) if avg_line_size > 0 else 0

                    if estimated_lines < 1000:
                        return f"~{estimated_lines}"
                    elif estimated_lines < 1000000:
                        return f"~{estimated_lines/1000:.1f}K"
                    else:
                        return f"~{estimated_lines/1000000:.1f}M"
        except:
            return "Unknown"


class DatasetSelector:
    """æ•°æ®é›†é€‰æ‹©å™¨"""

    def __init__(self, dataset_dir: str = "dataset"):
        self.dataset_dir = Path(dataset_dir)
        self.datasets: List[DatasetInfo] = []
        self.dataset_patterns = {
            'ml100k': r'.*100k.*',
            'movielens100k': r'.*M100K.*',
            'netflix': r'.*netflix.*',
            'filmtrust': r'.*filmtrust.*',
            'flimtrust': r'.*flimtrust.*',
            'ciaodvd': r'.*ciaodvd.*',
            'epinions': r'.*epinions.*',
            'amazon': r'.*amazon.*',
            'movielens1m': r'.*1m.*|.*movie.*1m.*',
            'tweetings': r'.*tweetings.*'
        }
        self._scan_datasets()

    def _scan_datasets(self):
        """æ‰«ææ•°æ®é›†ç›®å½•"""
        if not self.dataset_dir.exists():
            logger.warning(f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {self.dataset_dir}")
            return

        logger.info(f"æ‰«ææ•°æ®é›†ç›®å½•: {self.dataset_dir}")

        # è·å–æ‰€æœ‰æ•°æ®æ–‡ä»¶
        data_files = []
        for ext in ['*.txt', '*.csv', '*.dat']:
            data_files.extend(self.dataset_dir.glob(ext))

        # è§£ææ•°æ®é›†ä¿¡æ¯
        for file_path in data_files:
            dataset_info = self._parse_dataset_file(file_path)
            if dataset_info:
                self.datasets.append(dataset_info)

        # æŒ‰åç§°æ’åº
        self.datasets.sort(key=lambda x: x.name)
        logger.info(f"å‘ç° {len(self.datasets)} ä¸ªæ•°æ®é›†")

    def _parse_dataset_file(self, file_path: Path) -> Optional[DatasetInfo]:
        """è§£ææ•°æ®é›†æ–‡ä»¶ä¿¡æ¯"""
        filename = file_path.name.lower()

        # è·³è¿‡æ˜æ˜¾çš„éæ•°æ®é›†æ–‡ä»¶
        skip_patterns = ['test', 'sample', 'small', 'demo', 'temp']
        if any(pattern in filename for pattern in skip_patterns):
            # é™¤éæ˜¯å°æ•°æ®é›†ç”¨äºæµ‹è¯•
            if not any(size in filename for size in ['1percent', 'small_']):
                return None

        # è¯†åˆ«æ•°æ®é›†ç±»å‹
        dataset_name = self._identify_dataset_type(filename)
        display_name = self._generate_display_name(filename, dataset_name)

        return DatasetInfo(
            name=dataset_name,
            file_path=str(file_path),
            display_name=display_name
        )

    def _identify_dataset_type(self, filename: str) -> str:
        """è¯†åˆ«æ•°æ®é›†ç±»å‹"""
        filename_lower = filename.lower()

        for dataset_type, pattern in self.dataset_patterns.items():
            if re.search(pattern, filename_lower, re.IGNORECASE):
                return dataset_type

        # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨æ–‡ä»¶å
        base_name = Path(filename).stem
        return re.sub(r'[0-9]+|random|data|all|_', '', base_name).strip('_')

    def _generate_display_name(self, filename: str, dataset_type: str) -> str:
        """ç”Ÿæˆæ˜¾ç¤ºåç§°"""
        display_names = {
            'ml100k': 'MovieLens 100K',
            'movielens100k': 'MovieLens 100K',
            'netflix': 'Netflix',
            'filmtrust': 'FilmTrust',
            'flimtrust': 'FilmTrust',
            'ciaodvd': 'CiaoDVD',
            'epinions': 'Epinions',
            'amazon': 'Amazon',
            'movielens1m': 'MovieLens 1M',
            'tweetings': 'MovieTweetings'
        }

        base_display = display_names.get(dataset_type, dataset_type.title())

        # æ·»åŠ ç‰¹æ®Šæ ‡è¯†
        if 'small' in filename.lower() or '1percent' in filename.lower():
            base_display += ' (Small)'

        return base_display

    def display_datasets(self) -> None:
        """æ˜¾ç¤ºå¯ç”¨æ•°æ®é›†åˆ—è¡¨"""
        if not self.datasets:
            print("âŒ æœªå‘ç°å¯ç”¨çš„æ•°æ®é›†æ–‡ä»¶")
            return

        print("\n" + "="*80)
        print("ğŸ“Š å¯ç”¨æ•°æ®é›†åˆ—è¡¨")
        print("="*80)

        for i, dataset in enumerate(self.datasets, 1):
            print(f"[{i:2d}] {dataset.display_name}")
            print(f"     æ–‡ä»¶: {Path(dataset.file_path).name}")
            print(f"     å¤§å°: {dataset.file_size}")
            print()

        print(f"[{len(self.datasets)+1:2d}] å…¨éƒ¨é€‰æ‹©")
        print(f"[{len(self.datasets)+2:2d}] é€€å‡º")
        print("="*80)

    def get_user_selection(self) -> List[DatasetInfo]:
        """è·å–ç”¨æˆ·é€‰æ‹©çš„æ•°æ®é›†"""
        while True:
            self.display_datasets()

            try:
                choice = input("\nè¯·é€‰æ‹©æ•°æ®é›† (è¾“å…¥åºå·ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”): ").strip()

                if not choice:
                    continue

                # è§£æç”¨æˆ·è¾“å…¥
                selected_indices = []
                for item in choice.split(','):
                    item = item.strip()
                    if item.isdigit():
                        selected_indices.append(int(item))

                if not selected_indices:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„åºå·")
                    continue

                # å¤„ç†ç‰¹æ®Šé€‰æ‹©
                if len(self.datasets) + 2 in selected_indices:  # é€€å‡º
                    return []

                if len(self.datasets) + 1 in selected_indices:  # å…¨éƒ¨é€‰æ‹©
                    print(f"âœ… å·²é€‰æ‹©å…¨éƒ¨ {len(self.datasets)} ä¸ªæ•°æ®é›†")
                    return self.datasets.copy()

                # éªŒè¯é€‰æ‹©
                selected_datasets = []
                for idx in selected_indices:
                    if 1 <= idx <= len(self.datasets):
                        selected_datasets.append(self.datasets[idx-1])
                    else:
                        print(f"âŒ åºå· {idx} è¶…å‡ºèŒƒå›´")
                        break
                else:
                    # ç¡®è®¤é€‰æ‹©
                    print(f"\nâœ… å·²é€‰æ‹© {len(selected_datasets)} ä¸ªæ•°æ®é›†:")
                    for dataset in selected_datasets:
                        print(f"   - {dataset.display_name}")

                    confirm = input("\nç¡®è®¤é€‰æ‹©? (y/n): ").strip().lower()
                    if confirm in ['y', 'yes', 'æ˜¯']:
                        return selected_datasets

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆé€‰æ‹©")
                return []
            except Exception as e:
                print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
                continue

    def get_dataset_by_name(self, name: str) -> Optional[DatasetInfo]:
        """æ ¹æ®åç§°è·å–æ•°æ®é›†"""
        name_lower = name.lower()
        for dataset in self.datasets:
            if (dataset.name.lower() == name_lower or
                dataset.display_name.lower() == name_lower or
                name_lower in dataset.file_path.lower()):
                return dataset
        return None

    def get_all_datasets(self) -> List[DatasetInfo]:
        """è·å–æ‰€æœ‰æ•°æ®é›†"""
        return self.datasets.copy()

    def validate_dataset(self, dataset: DatasetInfo) -> bool:
        """éªŒè¯æ•°æ®é›†æ–‡ä»¶"""
        try:
            file_path = Path(dataset.file_path)

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not file_path.exists():
                logger.error(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
            if not os.access(file_path, os.R_OK):
                logger.error(f"æ•°æ®é›†æ–‡ä»¶ä¸å¯è¯»: {file_path}")
                return False

            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            with open(file_path, 'r', encoding='utf-8') as f:
                first_line = f.readline().strip()
                if not first_line:
                    logger.error(f"æ•°æ®é›†æ–‡ä»¶ä¸ºç©º: {file_path}")
                    return False

                # ç®€å•æ ¼å¼éªŒè¯ï¼ˆå‡è®¾æ˜¯ç”¨æˆ·ID ç‰©å“ID è¯„åˆ†çš„æ ¼å¼ï¼‰
                parts = first_line.split()
                if len(parts) < 3:
                    logger.warning(f"æ•°æ®é›†æ ¼å¼å¯èƒ½ä¸æ­£ç¡®: {file_path}")
                    # ä¸é˜»æ­¢ä½¿ç”¨ï¼Œåªæ˜¯è­¦å‘Š

            return True

        except Exception as e:
            logger.error(f"éªŒè¯æ•°æ®é›†æ—¶å‡ºé”™ {dataset.file_path}: {e}")
            return False


def main():
    """æµ‹è¯•å‡½æ•°"""
    selector = DatasetSelector()
    selected = selector.get_user_selection()

    if selected:
        print(f"\næœ€ç»ˆé€‰æ‹©äº† {len(selected)} ä¸ªæ•°æ®é›†:")
        for dataset in selected:
            print(f"  - {dataset.display_name}: {dataset.file_path}")
    else:
        print("\næœªé€‰æ‹©ä»»ä½•æ•°æ®é›†")


if __name__ == "__main__":
    main()

