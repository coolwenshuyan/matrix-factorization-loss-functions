#!/usr/bin/env python3
# Optimal parameter experiment\Optimal_parameter_experiment.py
"""
HPLæŸå¤±å‡½æ•°ä¸“ç”¨ä¼˜åŒ–å®éªŒ - é‡æ„ç‰ˆæœ¬ (æ‰¹é‡æ¨¡å¼)

ä¸“é—¨é’ˆå¯¹æ··åˆåˆ†æ®µæŸå¤±å‡½æ•°(HPL)çš„è¶…å‚æ•°ä¼˜åŒ–
é‡æ„ä¸ºç»Ÿä¸€çš„æ‰¹é‡å¤„ç†æ¨¡å¼ï¼Œåˆ é™¤é‡å¤ä»£ç ï¼Œæé«˜å¯ç»´æŠ¤æ€§
"""
from pathlib import Path
import sys
import os
import numpy as np
import time
import json
import glob
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

# å¯¼å…¥æ¨¡å—
try:
    from src.hyperopt.space import ParameterSpace
    from src.hyperopt.samplers import LatinHypercubeSampler
    from src.hyperopt.constraints import ConstraintManager
    from src.hyperopt.optimizer import HyperOptimizer
    from src.hyperopt.tracker import ExperimentTracker
    print("æˆåŠŸå¯¼å…¥hyperoptæ¨¡å—")
except ImportError as e:
    print(f"å¯¼å…¥hyperoptæ¨¡å—å¤±è´¥: {e}")

try:
    from data.data_manager import DataManager
    from src.models.mf_sgd import MatrixFactorizationSGD
    from src.models.initializers import NormalInitializer
    from src.models.regularizers import L2Regularizer
    from src.losses.hpl import HybridPiecewiseLoss
    from src.losses.standard import L2Loss
    print("æˆåŠŸå¯¼å…¥æ•°æ®å’Œæ¨¡å‹æ¨¡å—")
except ImportError as e:
    print(f"å¯¼å…¥æ•°æ®/æ¨¡å‹æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

try:
    from example_hyperopt import (
        SimpleParameterSpace, SimpleLatinHypercubeSampler,
        SimpleConstraintManager, SimpleHyperOptimizer, SimpleExperimentTracker
    )
    print("ç®€åŒ–ç‰ˆæœ¬ç±»å·²å‡†å¤‡å°±ç»ª")
except ImportError:
    print("è­¦å‘Šï¼šæ— æ³•å¯¼å…¥ç®€åŒ–ç‰ˆæœ¬ç±»")

# åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥çŸ­ä¿¡é€šçŸ¥æ¨¡å—
from utils.sms_notification import send_sms_notification

class DatasetAwareResultManager:
    """æ•°æ®é›†æ„ŸçŸ¥çš„ç»“æœç®¡ç†å™¨"""

    DATASET_CONFIGS = {
        'movielens100k': {
            'name': 'MovieLens100K',
            'size': '100K',
            'version': '2020-12-02',
            'short_name': 'ml100k'
        },
        'movielens1m': {
            'name': 'MovieLens1M',
            'size': '1M',
            'version': '2021-01-01',
            'short_name': 'ml1m'
        },
        'amazon_movies': {
            'name': 'Amazon Movies',
            'size': 'Various',
            'version': '2023',
            'short_name': 'amazon_mv'
        },
        'amazon_movies': {
            'name': 'Amazon Movies',
            'size': 'Various',
            'version': '2023',
            'short_name': 'amazon_mv'
        }
    }

    def __init__(self, dataset_name='movielens100k', dataset_file=None, base_dir=None):
        self.dataset_name = dataset_name
        self.dataset_file = dataset_file

        # ä¿®æ”¹ï¼šè®¾ç½®base_dirä¸ºå½“å‰è„šæœ¬åŒçº§ç›®å½•ä¸‹çš„results
        if base_dir is None:
            current_script_dir = os.path.dirname(os.path.abspath(__file__))
            base_dir = os.path.join(current_script_dir, 'results')

        self.base_dir = Path(base_dir)

        # è·å–æ•°æ®é›†ä¿¡æ¯
        self.dataset_info = self.DATASET_CONFIGS.get(dataset_name, {
            'name': dataset_name.title(),
            'size': 'Unknown',
            'version': 'Unknown',
            'short_name': dataset_name.lower()
        })

        # åˆ›å»ºæ•°æ®é›†ä¸“ç”¨ç›®å½•
        self.dataset_dir = self.base_dir / self.dataset_info['short_name']
        self.dataset_dir.mkdir(parents=True, exist_ok=True)
        self._create_subdirectories()

        # æ‰“å°ä¿å­˜è·¯å¾„ä¿¡æ¯
        print(f"ğŸ“ ç»“æœä¿å­˜ç›®å½•: {self.dataset_dir}")

    def _create_subdirectories(self):
        """åˆ›å»ºå¿…è¦çš„å­ç›®å½•"""
        subdirs = ['hpl_optimization', 'l2_optimization', 'comparison', 'models', 'reports', 'logs']
        for subdir in subdirs:
            (self.dataset_dir / subdir).mkdir(exist_ok=True)

    def generate_filename(self, experiment_type, file_format='json', include_timestamp=True):
        """ç”Ÿæˆæ•°æ®é›†ç›¸å…³çš„æ–‡ä»¶å"""
        timestamp = time.strftime("%Y%m%d_%H%M%S") if include_timestamp else ""
        parts = [self.dataset_info['short_name'], experiment_type, timestamp]
        parts = [part for part in parts if part]
        filename = "_".join(parts)
        return f"{filename}.{file_format}"

    def get_save_path(self, experiment_type, file_format='json'):
        """è·å–å®Œæ•´çš„ä¿å­˜è·¯å¾„"""
        subdir_map = {
            'hpl_optimization': 'hpl_optimization',
            'enhanced_hpl_optimization': 'hpl_optimization',
            'l2_optimization': 'l2_optimization',
            'hpl_vs_l2_comparison': 'comparison',
            'model_evaluation': 'reports',
            'training_log': 'logs'
        }
        subdir = subdir_map.get(experiment_type, 'hpl_optimization')
        filename = self.generate_filename(experiment_type, file_format)
        return self.dataset_dir / subdir / filename

    def save_experiment_results(self, results, experiment_type, metadata=None):
        """ä¿å­˜å®éªŒç»“æœï¼ŒåŒ…å«å®Œæ•´çš„æ•°æ®é›†ä¿¡æ¯"""
        try:
            save_data = {
                'dataset_info': {
                    'dataset_name': self.dataset_name,
                    'dataset_file': self.dataset_file,
                    'dataset_display_name': self.dataset_info['name'],
                    'dataset_size': self.dataset_info['size'],
                    'dataset_version': self.dataset_info['version']
                },
                'experiment_info': {
                    'experiment_type': experiment_type,
                    'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
                    'experiment_id': f"{experiment_type}_{time.strftime('%Y%m%d_%H%M%S')}"
                },
                'results': results
            }

            if metadata:
                save_data['metadata'] = metadata

            save_path = self.get_save_path(experiment_type, 'json')
            clean_data = self._convert_numpy_types(save_data)

            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump(clean_data, f, indent=2, ensure_ascii=False)

            print(f"\nğŸ“ å®éªŒç»“æœå·²ä¿å­˜åˆ°: {save_path}")
            print(f"   æ•°æ®é›†: {self.dataset_info['name']}")
            print(f"   å®éªŒç±»å‹: {experiment_type}")

            return save_path

        except Exception as e:
            print(f"ä¿å­˜å®éªŒç»“æœå¤±è´¥: {e}")
            return None

    def _convert_numpy_types(self, obj):
        """é€’å½’è½¬æ¢numpyç±»å‹"""
        if isinstance(obj, dict):
            return {key: self._convert_numpy_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_numpy_types(item) for item in obj]
        elif hasattr(obj, 'item'):
            return obj.item()
        elif hasattr(obj, 'tolist'):
            return obj.tolist()
        else:
            return obj


class OptimizationMonitor:
    """ç»Ÿä¸€çš„ä¼˜åŒ–ç›‘æ§å™¨"""

    def __init__(self, result_manager, experiment_type='optimization'):
        self.result_manager = result_manager
        self.experiment_type = experiment_type
        self.trial_history = []
        self.best_score_history = []

        # åˆ›å»ºå®æ—¶æ—¥å¿—æ–‡ä»¶ - ä¿®æ”¹ï¼šä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„results
        log_filename = f"{experiment_type}_log_{time.strftime('%Y%m%d_%H%M%S')}.txt"
        self.log_path = result_manager.dataset_dir / 'logs' / log_filename

        self.log_file = open(self.log_path, 'w', encoding='utf-8')
        self.log_file.write(f"ä¼˜åŒ–æ—¥å¿— - {result_manager.dataset_info['name']}\n")
        self.log_file.write(f"ä¿å­˜è·¯å¾„: {result_manager.dataset_dir}\n")
        self.log_file.write(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        self.log_file.write("="*60 + "\n\n")
        self.log_file.flush()

    def update(self, trial):
        """æ›´æ–°ç›‘æ§ä¿¡æ¯"""
        self.trial_history.append(trial)

        if not self.best_score_history:
            self.best_score_history.append(trial.score)
        else:
            self.best_score_history.append(
                min(self.best_score_history[-1], trial.score)
            )

        # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
        self.log_file.write(f"è¯•éªŒ {len(self.trial_history)}: åˆ†æ•°={trial.score:.4f}, é…ç½®={trial.config}\n")
        self.log_file.flush()

        # æ¯10æ¬¡è¯•éªŒæ‰“å°è¿›åº¦
        if len(self.trial_history) % 10 == 0:
            progress_msg = f"è¿›åº¦: {len(self.trial_history)} æ¬¡è¯•éªŒå®Œæˆï¼Œå½“å‰æœ€ä½³: {min(self.best_score_history):.4f}"
            print(progress_msg)
            self.log_file.write(f"\n{progress_msg}\n\n")
            self.log_file.flush()

    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¹¶ä¿å­˜"""
        report_data = {
            'total_trials': len(self.trial_history),
            'best_score': min(self.best_score_history) if self.best_score_history else None,
            'best_trial': min(self.trial_history, key=lambda x: x.score) if self.trial_history else None,
            'score_history': self.best_score_history,
            'convergence_analysis': self._analyze_convergence()
        }

        report_path = self.result_manager.save_experiment_results(
            results=report_data,
            experiment_type=f"{self.experiment_type}_report",
            metadata={'monitor_type': 'OptimizationMonitor'}
        )

        # å…³é—­æ—¥å¿—æ–‡ä»¶
        self.log_file.write(f"\nç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        self.log_file.write(f"æ€»è¯•éªŒæ¬¡æ•°: {len(self.trial_history)}\n")
        if self.best_score_history:
            self.log_file.write(f"æœ€ç»ˆæœ€ä½³åˆ†æ•°: {min(self.best_score_history):.4f}\n")
        self.log_file.close()

        print(f"\nğŸ“Š ç›‘æ§æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {self.log_path}")
        print(f"æ€»è¯•éªŒæ¬¡æ•°: {len(self.trial_history)}")
        if self.best_score_history:
            print(f"æœ€ç»ˆæœ€ä½³åˆ†æ•°: {min(self.best_score_history):.4f}")

    def _analyze_convergence(self):
        """åˆ†ææ”¶æ•›æƒ…å†µ"""
        if len(self.best_score_history) < 10:
            return {'status': 'insufficient_data'}

        recent_scores = self.best_score_history[-10:]
        improvement = recent_scores[0] - recent_scores[-1]

        return {
            'recent_improvement': improvement,
            'converged': improvement < 0.001,
            'best_trial_index': self.best_score_history.index(min(self.best_score_history)),
            'plateau_length': len(self.best_score_history) - self.best_score_history.index(min(self.best_score_history))
        }


class BaseObjectiveFunction:
    """åŸºç¡€ç›®æ ‡å‡½æ•°ç±»"""

    def __init__(self, data_manager):
        self.data_manager = data_manager
        self.n_users = data_manager.get_statistics()['n_users']
        self.n_items = data_manager.get_statistics()['n_items']
        self.train_data, self.val_data, self.test_data = data_manager.get_splits()

        print(f"ç›®æ ‡å‡½æ•°åˆå§‹åŒ–:")
        print(f"  è®­ç»ƒé›†: {len(self.train_data)} æ¡")
        print(f"  éªŒè¯é›†: {len(self.val_data)} æ¡")
        print(f"  æµ‹è¯•é›†: {len(self.test_data)} æ¡")

    def _create_model(self, config, loss_function):
        """åˆ›å»ºæ¨¡å‹çš„é€šç”¨æ–¹æ³•"""
        regularizer = L2Regularizer(lambda_reg=config['lambda_reg'])

        model = MatrixFactorizationSGD(
            n_users=self.n_users,
            n_items=self.n_items,
            n_factors=config['latent_factors'],
            learning_rate=config['learning_rate'],
            regularizer=regularizer,
            loss_function=loss_function,
            use_bias=True,
            global_mean=self.data_manager.global_mean or 0.0
        )

        initializer = NormalInitializer(mean=0.0, std=0.01)
        model.initialize_parameters(initializer)
        return model

    def _train_and_evaluate(self, model, n_epochs=50):
        """è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹çš„é€šç”¨æ–¹æ³•"""
        model.fit(
            train_data=self.train_data,
            val_data=self.val_data,
            n_epochs=n_epochs,
            verbose=0,
            early_stopping_patience=15
        )

        # éªŒè¯é›†è¯„ä¼°
        val_predictions = model.predict(
            self.val_data[:, 0].astype(int),
            self.val_data[:, 1].astype(int)
        )

        # è¿˜åŸåˆ°åŸå§‹å°ºåº¦
        if self.data_manager.global_mean is not None:
            val_predictions += self.data_manager.global_mean
            val_targets = self.val_data[:, 2] + self.data_manager.global_mean
        else:
            val_targets = self.val_data[:, 2]

        # è®¡ç®—RMSE
        rmse = np.sqrt(np.mean((val_predictions - val_targets) ** 2))
        return rmse

    def _format_config_output(self, config, rmse, loss_type):
        """æ ¼å¼åŒ–é…ç½®è¾“å‡º"""
        base_info = (f"{loss_type}é…ç½®: å­¦ä¹ ç‡={config['learning_rate']:.4f}, "
                    f"å› å­æ•°={config['latent_factors']}, "
                    f"æ­£åˆ™åŒ–={config['lambda_reg']:.6f}")

        if loss_type == "HPL" and 'delta1' in config:
            hpl_info = (f", Î´1={config['delta1']:.3f}, Î´2={config['delta2']:.3f}, "
                       f"l_max={config.get('l_max', 4.0):.2f}, c_sig={config.get('c_sigmoid', 1.0):.2f}")
            base_info += hpl_info

        print(f"{base_info}, RMSE={rmse:.4f}")


class HPLObjectiveFunction(BaseObjectiveFunction):
    """HPLä¸“ç”¨ç›®æ ‡å‡½æ•°"""

    def __call__(self, config):
        try:
            loss_function = HybridPiecewiseLoss(
                delta1=config['delta1'],
                delta2=config['delta2'],
                l_max=config.get('l_max', 4.0),
                c_sigmoid=config.get('c_sigmoid', 1.0)
            )

            model = self._create_model(config, loss_function)
            rmse = self._train_and_evaluate(model)
            self._format_config_output(config, rmse, "HPL")
            return rmse

        except Exception as e:
            print(f"HPLé…ç½®è¯„ä¼°å¤±è´¥ {config}: {e}")
            return 10.0


class L2ObjectiveFunction(BaseObjectiveFunction):
    """L2ä¸“ç”¨ç›®æ ‡å‡½æ•°"""

    def __call__(self, config):
        try:
            loss_function = L2Loss()
            model = self._create_model(config, loss_function)
            rmse = self._train_and_evaluate(model)
            self._format_config_output(config, rmse, "L2")
            return rmse

        except Exception as e:
            print(f"L2é…ç½®è¯„ä¼°å¤±è´¥ {config}: {e}")
            return 10.0


class ParameterSpaceFactory:
    """å‚æ•°ç©ºé—´å·¥å‚ç±»"""

    @staticmethod
    def create_hpl_space():
        """åˆ›å»ºHPLä¸“ç”¨å‚æ•°ç©ºé—´"""
        try:
            space = ParameterSpace()
        except:
            space = SimpleParameterSpace()

        # åŸºç¡€æ¨¡å‹å‚æ•°
        space.add_continuous('learning_rate', 0.01, 0.08, scale='log')
        space.add_discrete('latent_factors', 15, 75, step=5)
        space.add_continuous('lambda_reg', 0.001, 0.02, scale='log')

        # HPLä¸“ç”¨å‚æ•°
        space.add_continuous('delta1', 0.05, 1.5)
        space.add_continuous('delta2', 0.8, 4.0)
        space.add_continuous('l_max', 2.5, 6.0)
        space.add_continuous('c_sigmoid', 0.3, 3.0)

        print(f"HPLå‚æ•°ç©ºé—´ç»´åº¦: {space.get_dimension()}")
        return space

    @staticmethod
    def create_l2_space():
        """åˆ›å»ºL2ä¸“ç”¨å‚æ•°ç©ºé—´"""
        try:
            space = ParameterSpace()
        except:
            space = SimpleParameterSpace()

        space.add_continuous('learning_rate', 0.01, 0.08, scale='log')
        space.add_discrete('latent_factors', 15, 75, step=5)
        space.add_continuous('lambda_reg', 0.001, 0.02, scale='log')

        return space

    @staticmethod
    def create_enhanced_hpl_space():
        """åˆ›å»ºå¢å¼ºçš„HPLå‚æ•°ç©ºé—´"""
        try:
            space = ParameterSpace()
        except:
            space = SimpleParameterSpace()

        # åŸºç¡€æ¨¡å‹å‚æ•° - æ‰©å±•èŒƒå›´
        space.add_continuous('learning_rate', 0.005, 0.15, scale='log')
        space.add_discrete('latent_factors', 8, 120, step=8)
        space.add_continuous('lambda_reg', 0.0001, 0.05, scale='log')

        # HPLä¸“ç”¨å‚æ•° - æ‰©å±•èŒƒå›´
        space.add_continuous('delta1', 0.05, 1.0)
        space.add_continuous('delta2', 0.3, 3.5)
        space.add_continuous('l_max', 1.5, 6.0)
        space.add_continuous('c_sigmoid', 0.2, 3.0)

        print(f"å¢å¼ºHPLå‚æ•°ç©ºé—´ç»´åº¦: {space.get_dimension()}")
        return space


class ConstraintFactory:
    """çº¦æŸå·¥å‚ç±»"""

    @staticmethod
    def create_hpl_constraints():
        """åˆ›å»ºHPLä¸“ç”¨çº¦æŸæ¡ä»¶"""
        try:
            constraints = ConstraintManager()
        except:
            constraints = SimpleConstraintManager()

        # æ ¸å¿ƒçº¦æŸï¼šdelta1 < delta2
        constraints.add_relation('delta1', 'delta2', '<')
        return constraints


class OptimizerFactory:
    """ä¼˜åŒ–å™¨å·¥å‚ç±»"""

    @staticmethod
    def create_optimizer(objective, space, constraints=None, name='optimization'):
        """åˆ›å»ºä¼˜åŒ–å™¨"""
        try:
            sampler = LatinHypercubeSampler(space, seed=42)
            tracker = ExperimentTracker(name, backend='memory')
            optimizer = HyperOptimizer(
                objective_fn=objective,
                space=space,
                sampler=sampler,
                constraints=constraints,
                tracker=tracker,
                maximize=False,
                seed=42
            )
            print("ä½¿ç”¨å®Œæ•´ç‰ˆhyperoptç»„ä»¶")
        except:
            sampler = SimpleLatinHypercubeSampler(space, seed=42)
            tracker = SimpleExperimentTracker(name, backend='memory')
            optimizer = SimpleHyperOptimizer(
                objective_fn=objective,
                space=space,
                sampler=sampler,
                constraints=constraints,
                tracker=tracker,
                maximize=False,
                seed=42
            )
            print("ä½¿ç”¨ç®€åŒ–ç‰ˆhyperoptç»„ä»¶")

        return optimizer


def setup_data_manager(dataset_name='movielens100k',
                      dataset_file='dataset/20201202M100K_data_all_random.txt'):
    """è®¾ç½®æ•°æ®ç®¡ç†å™¨"""
    print(f"å‡†å¤‡æ•°æ®é›†: {dataset_name}")

    # ç¡®ä¿æ•°æ®é›†å·²æ³¨å†Œ
    from data.loader import DatasetLoader
    from data.dataset import MovieLens100K, MovieLens1M, Netflix, AmazonMI, CiaoDVD, Epinions, FilmTrust, MovieTweetings

    # è·å–æ•°æ®é›†ç±»
    dataset_classes = {
        'movielens100k': MovieLens100K,
        'movielens1m': MovieLens1M,
        'netflix': Netflix,
        'amazonmi': AmazonMI,
        'ciaodvd': CiaoDVD,
        'epinions': Epinions,
        'filmtrust': FilmTrust,
        'movietweetings': MovieTweetings
    }

    # ä»¿ç…§ example_data newDataset.py çš„æ–¹å¼æ³¨å†Œæ•°æ®é›†
    # ç›´æ¥æ³¨å†Œï¼Œä¸æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    dataset_class = dataset_classes.get(dataset_name.lower(), MovieLens100K)
    DatasetLoader.register_dataset(dataset_name, dataset_class)
    print(f"âœ“ å·²æ³¨å†Œæ•°æ®é›†: {dataset_name}")
    print(f"âœ“ å½“å‰æ³¨å†Œçš„æ•°æ®é›†: {list(DatasetLoader.DATASET_REGISTRY.keys())}")

    data_config = {
        'random_seed': 42,
        'train_ratio': 0.8,
        'val_ratio': 0.1,
        'test_ratio': 0.1,
        'batch_size': 128,
        'shuffle': True,
        'center_data': True,
        'ensure_user_in_train': True
    }

    data_manager = DataManager(data_config)

    # æ‰“å°è¯¦ç»†çš„åŠ è½½ä¿¡æ¯
    print(f"DEBUG: å°è¯•åŠ è½½æ•°æ®é›† '{dataset_name}'")
    print(f"DEBUG: æ•°æ®æ–‡ä»¶è·¯å¾„: '{dataset_file}'")
    print(f"DEBUG: å½“å‰æ³¨å†Œçš„æ•°æ®é›†: {list(DatasetLoader.DATASET_REGISTRY.keys())}")

    try:
        data_manager.load_dataset(dataset_name, dataset_file)
        data_manager.preprocess()
        print(f"âœ“ æ•°æ®é›† {dataset_name} åŠ è½½å’Œé¢„å¤„ç†æˆåŠŸ")
        # æ‰“å°æ•°æ®æ‘˜è¦
        data_manager.print_summary()
        return data_manager
    except Exception as e:
        print(f"åŠ è½½ {dataset_name} æ•°æ®é›†å¤±è´¥: {e}")
        raise


def run_optimization(loss_type='hpl', enhanced=False, n_trials=40,
                    dataset_name='movielens100k',
                    dataset_file='dataset/20201202M100K_data_all_random.txt'):
    """ç»Ÿä¸€çš„ä¼˜åŒ–è¿è¡Œå‡½æ•°"""
    print(f"å¼€å§‹{loss_type.upper()}ä¼˜åŒ– ({'å¢å¼ºç‰ˆ' if enhanced else 'åŸºç¡€ç‰ˆ'})...")

    # è®¾ç½®æ•°æ®å’Œç»“æœç®¡ç†å™¨
    data_manager = setup_data_manager(dataset_name, dataset_file)
    result_manager = DatasetAwareResultManager(dataset_name, dataset_file)
    monitor = OptimizationMonitor(result_manager, f'{loss_type}_optimization')

    # åˆ›å»ºç›®æ ‡å‡½æ•°å’Œå‚æ•°ç©ºé—´
    if loss_type == 'hpl':
        objective = HPLObjectiveFunction(data_manager)
        if enhanced:
            space = ParameterSpaceFactory.create_enhanced_hpl_space()
        else:
            space = ParameterSpaceFactory.create_hpl_space()
        constraints = ConstraintFactory.create_hpl_constraints()
    else:  # l2
        objective = L2ObjectiveFunction(data_manager)
        space = ParameterSpaceFactory.create_l2_space()
        constraints = None

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = OptimizerFactory.create_optimizer(objective, space, constraints, f'{loss_type}_optimization')

    # è¿è¡Œä¼˜åŒ–
    start_time = time.time()
    best_trial = optimizer.optimize(
        n_trials=n_trials,
        no_improvement_rounds=15,
        batch_size=1
    )
    end_time = time.time()

    # è¾“å‡ºç»“æœ
    print(f"\n{loss_type.upper()}ä¼˜åŒ–ç»“æœ:")
    if best_trial:
        print(f"æœ€ä½³é…ç½®: {best_trial.config}")
        print(f"æœ€ä½³åˆ†æ•°: {best_trial.score:.4f}")
        print(f"ä¼˜åŒ–è€—æ—¶: {end_time - start_time:.2f}ç§’")

        # ä¿å­˜ç»“æœ
        optimization_results = {
            'best_config': best_trial.config,
            'best_score': best_trial.score,
            'optimization_time': end_time - start_time,
            'optimizer_results': optimizer.get_results()
        }

        result_manager.save_experiment_results(
            results=optimization_results,
            experiment_type=f'{loss_type}_optimization',
            metadata={'algorithm': 'Latin Hypercube Sampling', 'enhanced': enhanced}
        )

    monitor.generate_final_report()
    return optimizer, best_trial, result_manager


def run_hpl_vs_l2_comparison(n_trials=40,
                            dataset_name='movielens100k',
                            dataset_file='dataset/20201202M100K_data_all_random.txt'):
    """HPLä¸L2æŸå¤±å‡½æ•°çš„å¯¹æ¯”"""
    print("\n" + "="*60)
    print("HPL vs L2 å¯¹æ¯”å®éªŒ")
    print("="*60)

    # è¿è¡ŒHPLä¼˜åŒ–
    print("\n1. è¿è¡ŒHPLä¼˜åŒ–...")
    hpl_optimizer, hpl_best, result_manager = run_optimization(
        'hpl', False, n_trials, dataset_name, dataset_file
    )

    # è¿è¡ŒL2ä¼˜åŒ–
    print("\n2. è¿è¡ŒL2ä¼˜åŒ–...")
    l2_optimizer, l2_best, _ = run_optimization(
        'l2', False, n_trials, dataset_name, dataset_file
    )

    # å¯¹æ¯”åˆ†æ
    print("\n" + "="*60)
    print("å¯¹æ¯”ç»“æœ")
    print("="*60)

    hpl_rmse = hpl_best.score if hpl_best else float('inf')
    l2_rmse = l2_best.score if l2_best else float('inf')

    print(f"{'æŸå¤±å‡½æ•°':<12} {'æœ€ä½³RMSE':<12}")
    print("-" * 25)
    print(f"{'HPL':<12} {hpl_rmse:<12.4f}")
    print(f"{'L2':<12} {l2_rmse:<12.4f}")

    if hpl_rmse < l2_rmse:
        improvement = (l2_rmse - hpl_rmse) / l2_rmse * 100
        print(f"\nğŸ‰ HPLè¡¨ç°æ›´ä¼˜! æ”¹è¿›äº†: {improvement:.2f}%")
        winner = 'HPL'
    elif l2_rmse < hpl_rmse:
        degradation = (hpl_rmse - l2_rmse) / l2_rmse * 100
        print(f"\nğŸ“Š L2è¡¨ç°æ›´ä¼˜ï¼ŒHPLå·®äº†: {degradation:.2f}%")
        winner = 'L2'
    else:
        print(f"\nğŸ¤ ä¸¤ç§æŸå¤±å‡½æ•°è¡¨ç°ç›¸å½“")
        winner = 'Tie'

    # ä¿å­˜å¯¹æ¯”ç»“æœ
    comparison_results = {
        'winner': winner,
        'hpl_rmse': hpl_rmse,
        'l2_rmse': l2_rmse,
        'improvement_percentage': (l2_rmse - hpl_rmse) / l2_rmse * 100 if l2_rmse != 0 else 0,
        'hpl_config': hpl_best.config if hpl_best else None,
        'l2_config': l2_best.config if l2_best else None
    }

    result_manager.save_experiment_results(
        results=comparison_results,
        experiment_type='hpl_vs_l2_comparison',
        metadata={'comparison_type': 'HPL_vs_L2'}
    )

    return comparison_results


def guess_dataset_type(filename):
    """æ ¹æ®æ–‡ä»¶åçŒœæµ‹æ•°æ®é›†ç±»å‹"""
    filename = filename.lower()

    # è¿”å›ä¸æ•°æ®é›†ç±»å¯¹åº”çš„åç§°
    if 'm100k' in filename or 'movielens100k' in filename:
        return 'movielens100k'
    elif 'netflix' in filename:
        return 'netflix'
    elif 'm1m' in filename or 'movielens1m' in filename or 'moive1m' in filename:
        return 'movielens1m'
    elif 'amazon' in filename and ('musical' in filename or 'mi' in filename):
        return 'amazonmi'
    elif 'ciaodvd' in filename:
        return 'ciaodvd'
    elif 'epinions' in filename:
        return 'epinions'
    elif 'filmtrust' in filename or 'flimtrust' in filename:
        return 'filmtrust'
    elif 'movietweetings' in filename or 'moivetweetings' in filename:
        return 'movietweetings'
    else:
        # å¦‚æœæ— æ³•è¯†åˆ«ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤å€¼
        return 'movielens100k'  # æœªçŸ¥ç±»å‹


def check_file_format(file_path):
    """æ£€æŸ¥æ–‡ä»¶æ ¼å¼å¹¶æ˜¾ç¤ºå‰å‡ è¡Œï¼Œå°è¯•è‡ªåŠ¨ä¿®å¤æ ¼å¼é—®é¢˜"""
    try:
        print(f"\næ£€æŸ¥æ–‡ä»¶æ ¼å¼: {os.path.basename(file_path)}")
        # æ–‡ä»¶çš„æ ¼å¼ä¸º  [user_id,movie_id,rating]
        print("1. æ–‡ä»¶æ ¼å¼ä¸ºæ¯è¡Œ: [user_id, movie_id, rating]")
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f.readlines()[:10]]

        print("æ–‡ä»¶å‰10è¡Œå†…å®¹:")
        for i, line in enumerate(lines, 1):
            print(f"{i}: {line}")

        # å°è¯•æ£€æµ‹æ–‡ä»¶æ ¼å¼
        format_type = "æœªçŸ¥"
        format_issues = []

        # æ£€æŸ¥æ˜¯å¦ä¸ºJSONæ ¼å¼
        if lines and lines[0].startswith('[') and lines[0].endswith(']'):
            format_type = "[user_id, item_id, rating]æ ¼å¼"
            # æ£€æŸ¥æ˜¯å¦æœ‰æ ¼å¼é—®é¢˜
            try:
                import ast
                for line in lines:
                    data = ast.literal_eval(line)
                    if len(data) != 3:
                        format_issues.append(f"æ•°æ®é¡¹æ•°é‡ä¸æ˜¯3: {line}")
            except:
                format_issues.append("JSONæ ¼å¼è§£æå¤±è´¥")

        # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ¶è¡¨ç¬¦åˆ†éš”
        elif lines and '\t' in lines[0]:
            format_type = "åˆ¶è¡¨ç¬¦åˆ†éš”æ ¼å¼"
            # æ£€æŸ¥æ¯è¡Œçš„åˆ—æ•°æ˜¯å¦ä¸€è‡´
            cols = [len(line.split('\t')) for line in lines if line]
            if len(set(cols)) > 1:
                format_issues.append(f"åˆ—æ•°ä¸ä¸€è‡´: {cols}")

        # æ£€æŸ¥æ˜¯å¦ä¸ºé€—å·åˆ†éš”
        elif lines and ',' in lines[0]:
            format_type = "é€—å·åˆ†éš”æ ¼å¼"
            # æ£€æŸ¥æ¯è¡Œçš„åˆ—æ•°æ˜¯å¦ä¸€è‡´
            cols = [len(line.split(',')) for line in lines if line]
            if len(set(cols)) > 1:
                format_issues.append(f"åˆ—æ•°ä¸ä¸€è‡´: {cols}")

        print(f"æ¨æµ‹æ–‡ä»¶æ ¼å¼: {format_type}")

        if format_issues:
            print("âš ï¸ æ£€æµ‹åˆ°æ½œåœ¨æ ¼å¼é—®é¢˜:")
            for issue in format_issues:
                print(f"  - {issue}")

            # è¯¢é—®æ˜¯å¦å°è¯•ä¿®å¤
            fix = input("æ˜¯å¦å°è¯•è‡ªåŠ¨ä¿®å¤æ ¼å¼é—®é¢˜? (y/n, é»˜è®¤n): ").strip().lower()
            if fix == 'y':
                fixed_path = fix_file_format(file_path, format_type)
                if fixed_path:
                    print(f"âœ… å·²ä¿®å¤æ ¼å¼é—®é¢˜ï¼Œæ–°æ–‡ä»¶: {fixed_path}")
                    return fixed_path
                else:
                    print("âŒ ä¿®å¤å¤±è´¥")

        # æç¤ºç”¨æˆ·ç¡®è®¤
        confirm = input("æ˜¯å¦ç»§ç»­ä½¿ç”¨æ­¤æ–‡ä»¶? (y/n, é»˜è®¤y): ").strip().lower()
        if confirm == 'n':
            return None
        return file_path
    except Exception as e:
        print(f"æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ—¶å‡ºé”™: {e}")
        return None


def fix_file_format(file_path, format_type):
    """å°è¯•ä¿®å¤æ–‡ä»¶æ ¼å¼é—®é¢˜"""
    try:
        base_name = os.path.basename(file_path)
        dir_name = os.path.dirname(file_path)
        fixed_path = os.path.join(dir_name, f"fixed_{base_name}")

        with open(file_path, 'r', encoding='utf-8') as f_in:
            with open(fixed_path, 'w', encoding='utf-8') as f_out:
                for line in f_in:
                    line = line.strip()
                    if not line:  # è·³è¿‡ç©ºè¡Œ
                        continue

                    # æ ¹æ®ä¸åŒæ ¼å¼è¿›è¡Œä¿®å¤
                    if format_type == "[user_id, item_id, rating]æ ¼å¼":
                        try:
                            import ast
                            data = ast.literal_eval(line)
                            if len(data) >= 3:  # ç¡®ä¿è‡³å°‘æœ‰3ä¸ªå…ƒç´ 
                                # åªä¿ç•™å‰3ä¸ªå…ƒç´ 
                                f_out.write(f"[{data[0]}, {data[1]}, {data[2]}]\n")
                        except:
                            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•çš„æ ¼å¼ä¿®å¤
                            line = line.replace('[', '').replace(']', '')
                            parts = [p.strip() for p in line.split(',')]
                            if len(parts) >= 3:
                                f_out.write(f"[{parts[0]}, {parts[1]}, {parts[2]}]\n")

                    elif format_type == "åˆ¶è¡¨ç¬¦åˆ†éš”æ ¼å¼":
                        parts = [p.strip() for p in line.split('\t')]
                        if len(parts) >= 3:  # ç¡®ä¿è‡³å°‘æœ‰3ä¸ªå…ƒç´ 
                            # åªä¿ç•™å‰3ä¸ªå…ƒç´ 
                            f_out.write(f"{parts[0]}\t{parts[1]}\t{parts[2]}\n")

                    elif format_type == "é€—å·åˆ†éš”æ ¼å¼":
                        parts = [p.strip() for p in line.split(',')]
                        if len(parts) >= 3:  # ç¡®ä¿è‡³å°‘æœ‰3ä¸ªå…ƒç´ 
                            # åªä¿ç•™å‰3ä¸ªå…ƒç´ 
                            f_out.write(f"{parts[0]},{parts[1]},{parts[2]}\n")

                    else:  # æœªçŸ¥æ ¼å¼ï¼Œå°è¯•é€šç”¨ä¿®å¤
                        # ç§»é™¤æ‰€æœ‰éæ•°å­—ã€é€—å·ã€ç‚¹ã€æ–¹æ‹¬å·å’Œç©ºæ ¼çš„å­—ç¬¦
                        import re
                        cleaned = re.sub(r'[^\d\.,\[\]\s]', '', line)
                        # å°è¯•æå–3ä¸ªæ•°å­—
                        numbers = re.findall(r'\d+(?:\.\d+)?', cleaned)
                        if len(numbers) >= 3:
                            f_out.write(f"[{numbers[0]}, {numbers[1]}, {numbers[2]}]\n")

        # æ£€æŸ¥ä¿®å¤åçš„æ–‡ä»¶æ˜¯å¦æœ‰å†…å®¹
        if os.path.getsize(fixed_path) > 0:
            print(f"âœ… ä¿®å¤åçš„æ–‡ä»¶ä¿å­˜è‡³: {fixed_path}")
            return fixed_path
        else:
            os.remove(fixed_path)  # åˆ é™¤ç©ºæ–‡ä»¶
            return None
    except Exception as e:
        print(f"ä¿®å¤æ–‡ä»¶æ ¼å¼æ—¶å‡ºé”™: {e}")
        return None


def scan_available_datasets(dataset_dir):
    """æ‰«æå¹¶åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†"""
    print(f"\nğŸ” æ‰«ææ•°æ®é›†ç›®å½•: {dataset_dir}")

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_dir):
        print(f"âš ï¸ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
        try:
            os.makedirs(dataset_dir, exist_ok=True)
            print(f"âœ… å·²åˆ›å»ºæ•°æ®é›†ç›®å½•: {dataset_dir}")
        except Exception as e:
            print(f"âŒ æ— æ³•åˆ›å»ºæ•°æ®é›†ç›®å½•: {e}")
            return []

    # è·å–æ‰€æœ‰txtæ–‡ä»¶
    pattern = os.path.join(dataset_dir, '*.txt')
    dataset_files = glob.glob(pattern)

    if not dataset_files:
        print(f"âŒ åœ¨ {dataset_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• .txt æ•°æ®é›†æ–‡ä»¶")
        print("è¯·å°†æ•°æ®é›†æ–‡ä»¶æ”¾å…¥è¯¥ç›®å½•åé‡æ–°è¿è¡Œç¨‹åº")
        return []

    print(f"âœ… æ‰¾åˆ° {len(dataset_files)} ä¸ªæ•°æ®é›†æ–‡ä»¶")
    return dataset_files


def create_dataset_mapping(dataset_files):
    """åˆ›å»ºæ–‡ä»¶ååˆ°æ•°æ®é›†ç±»å‹çš„æ˜ å°„"""
    dataset_map = {}

    print("\nğŸ“‹ å¯ç”¨æ•°æ®é›†åˆ—è¡¨:")
    print("-" * 80)
    print(f"{'åºå·':<4} {'æ–‡ä»¶å':<40} {'æ¨æµ‹ç±»å‹':<20} {'æ–‡ä»¶å¤§å°'}")
    print("-" * 80)

    for i, file_path in enumerate(dataset_files, 1):
        filename = os.path.basename(file_path)
        dataset_type = guess_dataset_type(filename)

        # è·å–æ–‡ä»¶å¤§å°
        try:
            file_size = os.path.getsize(file_path)
            if file_size > 1024 * 1024:  # MB
                size_str = f"{file_size / (1024 * 1024):.1f}MB"
            elif file_size > 1024:  # KB
                size_str = f"{file_size / 1024:.1f}KB"
            else:
                size_str = f"{file_size}B"
        except:
            size_str = "æœªçŸ¥"

        dataset_map[str(i)] = {
            'dataset_type': dataset_type,
            'file_path': file_path,
            'filename': filename,
            'file_size': size_str
        }

        print(f"{i:<4} {filename:<40} {dataset_type:<20} {size_str}")

    print("-" * 80)
    return dataset_map


def get_user_dataset_selection(dataset_map):
    """è·å–ç”¨æˆ·çš„æ•°æ®é›†é€‰æ‹©"""
    print("\nğŸ“ æ•°æ®é›†é€‰æ‹©:")
    print("- è¾“å…¥åºå·é€‰æ‹©å•ä¸ªæ•°æ®é›† (ä¾‹å¦‚: 1)")
    print("- è¾“å…¥å¤šä¸ªåºå·é€‰æ‹©å¤šä¸ªæ•°æ®é›† (ä¾‹å¦‚: 1,3,5)")
    print("- è¾“å…¥ 'all' é€‰æ‹©æ‰€æœ‰æ•°æ®é›†")

    while True:
        choice = input("\nè¯·é€‰æ‹©æ•°æ®é›†: ").strip()

        if not choice:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆé€‰æ‹©")
            continue

        selected_datasets = []

        if choice.lower() == 'all':
            selected_datasets = list(dataset_map.values())
            print(f"âœ… å·²é€‰æ‹©æ‰€æœ‰ {len(selected_datasets)} ä¸ªæ•°æ®é›†")
            break

        # è§£æç”¨æˆ·è¾“å…¥
        try:
            choices = [c.strip() for c in choice.split(',')]
            for c in choices:
                if c in dataset_map:
                    selected_datasets.append(dataset_map[c])
                else:
                    print(f"âŒ æ— æ•ˆé€‰æ‹©: {c}")
                    raise ValueError("æ— æ•ˆé€‰æ‹©")

            if selected_datasets:
                print(f"âœ… å·²é€‰æ‹© {len(selected_datasets)} ä¸ªæ•°æ®é›†:")
                for ds in selected_datasets:
                    print(f"   - {ds['filename']} ({ds['dataset_type']})")
                break
            else:
                print("âŒ æœªé€‰æ‹©ä»»ä½•æ•°æ®é›†")

        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„åºå·")
            continue

    return selected_datasets


def batch_check_file_formats(selected_datasets):
    """æ‰¹é‡æ£€æŸ¥å’Œä¿®å¤æ–‡ä»¶æ ¼å¼"""
    print("\nğŸ”§ æ‰¹é‡æ£€æŸ¥æ–‡ä»¶æ ¼å¼...")

    processed_datasets = []
    skipped_datasets = []

    for i, dataset_info in enumerate(selected_datasets, 1):
        print(f"\nå¤„ç† {i}/{len(selected_datasets)}: {dataset_info['filename']}")

        try:
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            fixed_file = check_file_format(dataset_info['file_path'])

            if fixed_file:
                # æ›´æ–°æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæ–‡ä»¶è¢«ä¿®å¤ï¼‰
                if fixed_file != dataset_info['file_path']:
                    print(f"âœ… ä½¿ç”¨ä¿®å¤åçš„æ–‡ä»¶: {os.path.basename(fixed_file)}")
                    dataset_info['file_path'] = fixed_file
                    dataset_info['format_fixed'] = True
                else:
                    dataset_info['format_fixed'] = False

                processed_datasets.append(dataset_info)
                print(f"âœ… {dataset_info['filename']} æ ¼å¼æ£€æŸ¥é€šè¿‡")
            else:
                print(f"âŒ {dataset_info['filename']} æ ¼å¼æ£€æŸ¥å¤±è´¥ï¼Œè·³è¿‡")
                skipped_datasets.append(dataset_info)

        except Exception as e:
            print(f"âŒ å¤„ç† {dataset_info['filename']} æ—¶å‡ºé”™: {e}")
            skipped_datasets.append(dataset_info)

    print(f"\nğŸ“Š æ ¼å¼æ£€æŸ¥ç»“æœ:")
    print(f"   âœ… æˆåŠŸ: {len(processed_datasets)} ä¸ª")
    print(f"   âŒ è·³è¿‡: {len(skipped_datasets)} ä¸ª")

    if skipped_datasets:
        print("\nâš ï¸ è·³è¿‡çš„æ•°æ®é›†:")
        for ds in skipped_datasets:
            print(f"   - {ds['filename']}")

    return processed_datasets


def get_experiment_type_selection():
    """è·å–ç”¨æˆ·çš„å®éªŒç±»å‹é€‰æ‹©"""
    print("\nğŸ§ª å®éªŒç±»å‹é€‰æ‹©:")
    print("1. HPLåŸºç¡€ä¼˜åŒ– (40æ¬¡è¯•éªŒ)")
    print("2. HPLå¢å¼ºä¼˜åŒ– (150æ¬¡è¯•éªŒï¼Œæ‰©å±•å‚æ•°ç©ºé—´)")
    print("3. HPL vs L2 å¯¹æ¯”å®éªŒ (åˆ†åˆ«ä¼˜åŒ–åå¯¹æ¯”)")

    while True:
        choice = input("\né€‰æ‹©å®éªŒç±»å‹ (1-3, é»˜è®¤1): ").strip()

        if not choice:
            choice = '1'

        if choice in ['1', '2', '3']:
            experiment_types = {
                '1': ('hpl_basic', 'HPLåŸºç¡€ä¼˜åŒ–'),
                '2': ('hpl_enhanced', 'HPLå¢å¼ºä¼˜åŒ–'),
                '3': ('hpl_vs_l2', 'HPL vs L2 å¯¹æ¯”')
            }

            exp_type, exp_name = experiment_types[choice]
            print(f"âœ… å·²é€‰æ‹©: {exp_name}")
            return exp_type
        else:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆé€‰æ‹© (1-3)")


def execute_single_dataset_experiment(dataset_info, experiment_type):
    """æ‰§è¡Œå•ä¸ªæ•°æ®é›†çš„å®éªŒ"""
    dataset_name = dataset_info['dataset_type']
    dataset_file = dataset_info['file_path']
    filename = dataset_info['filename']

    print(f"\nğŸš€ å¼€å§‹å®éªŒ: {filename}")
    print(f"   æ•°æ®é›†ç±»å‹: {dataset_name}")
    print(f"   å®éªŒç±»å‹: {experiment_type}")

    start_time = time.time()

    try:
        # åŠ¨æ€æ³¨å†Œæ•°æ®é›†
        if not register_dataset(dataset_name):
            raise Exception(f"æ•°æ®é›†æ³¨å†Œå¤±è´¥: {dataset_name}")

        # è®¾ç½®æ•°æ®ç®¡ç†å™¨
        data_manager = setup_data_manager(dataset_name, dataset_file)

        # æ ¹æ®å®éªŒç±»å‹æ‰§è¡Œç›¸åº”çš„å®éªŒ
        if experiment_type == 'hpl_basic':
            optimizer, best_trial, result_manager = run_optimization(
                'hpl', False, 40, dataset_name, dataset_file
            )
            result = {
                'type': 'hpl_basic',
                'best_trial': best_trial,
                'best_score': best_trial.score if best_trial else None,
                'best_config': best_trial.config if best_trial else None
            }

        elif experiment_type == 'hpl_enhanced':
            optimizer, best_trial, result_manager = run_optimization(
                'hpl', True, 150, dataset_name, dataset_file
            )
            result = {
                'type': 'hpl_enhanced',
                'best_trial': best_trial,
                'best_score': best_trial.score if best_trial else None,
                'best_config': best_trial.config if best_trial else None
            }

        elif experiment_type == 'hpl_vs_l2':
            comparison_result = run_hpl_vs_l2_comparison(40, dataset_name, dataset_file)
            result = {
                'type': 'hpl_vs_l2',
                'comparison_result': comparison_result,
                'winner': comparison_result.get('winner'),
                'hpl_score': comparison_result.get('hpl_rmse'),
                'l2_score': comparison_result.get('l2_rmse'),
                'improvement': comparison_result.get('improvement_percentage')
            }

        else:
            raise ValueError(f"æœªçŸ¥å®éªŒç±»å‹: {experiment_type}")

        end_time = time.time()
        duration = end_time - start_time

        result.update({
            'status': 'success',
            'duration': duration,
            'dataset_info': dataset_info
        })

        print(f"âœ… {filename} å®éªŒå®Œæˆ ({duration:.1f}ç§’)")
        return result

    except Exception as e:
        end_time = time.time()
        duration = end_time - start_time

        print(f"âŒ {filename} å®éªŒå¤±è´¥: {e}")
        traceback.print_exc()

        return {
            'status': 'failed',
            'error': str(e),
            'duration': duration,
            'dataset_info': dataset_info
        }


def generate_multi_dataset_summary(all_results, experiment_type):
    """ç”Ÿæˆå¤šæ•°æ®é›†å®éªŒæ±‡æ€»æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("å¤šæ•°æ®é›†å®éªŒæ±‡æ€»æŠ¥å‘Š")
    print("="*80)

    # ç»Ÿè®¡ä¿¡æ¯
    total_datasets = len(all_results)
    successful_datasets = len([r for r in all_results.values() if r['status'] == 'success'])
    failed_datasets = total_datasets - successful_datasets
    total_duration = sum(r['duration'] for r in all_results.values())

    print(f"\nğŸ“Š å®éªŒç»Ÿè®¡:")
    print(f"   æ€»æ•°æ®é›†æ•°: {total_datasets}")
    print(f"   æˆåŠŸæ•°é‡: {successful_datasets}")
    print(f"   å¤±è´¥æ•°é‡: {failed_datasets}")
    print(f"   æ€»è€—æ—¶: {total_duration:.1f}ç§’ ({total_duration/60:.1f}åˆ†é’Ÿ)")
    print(f"   å¹³å‡è€—æ—¶: {total_duration/total_datasets:.1f}ç§’/æ•°æ®é›†")

    # è¯¦ç»†ç»“æœ
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    print("-" * 80)

    if experiment_type in ['hpl_basic', 'hpl_enhanced']:
        print(f"{'æ•°æ®é›†':<30} {'çŠ¶æ€':<8} {'æœ€ä½³RMSE':<12} {'è€—æ—¶(ç§’)':<10}")
        print("-" * 80)

        successful_results = []
        for dataset_name, result in all_results.items():
            status = "âœ…æˆåŠŸ" if result['status'] == 'success' else "âŒå¤±è´¥"

            if result['status'] == 'success':
                rmse = result.get('best_score', 'N/A')
                rmse_str = f"{rmse:.4f}" if rmse and rmse != 'N/A' else 'N/A'
                successful_results.append((dataset_name, rmse))
            else:
                rmse_str = f"é”™è¯¯: {result.get('error', 'Unknown')[:20]}..."

            duration = result.get('duration', 0)
            print(f"{dataset_name:<30} {status:<8} {rmse_str:<12} {duration:<10.1f}")

        # æ’åºæ˜¾ç¤ºæœ€ä½³ç»“æœ
        if successful_results:
            print(f"\nğŸ† æœ€ä½³è¡¨ç°æ’åº:")
            successful_results.sort(key=lambda x: x[1])
            for i, (dataset_name, rmse) in enumerate(successful_results, 1):
                print(f"   {i}. {dataset_name}: {rmse:.4f}")

    elif experiment_type == 'hpl_vs_l2':
        print(f"{'æ•°æ®é›†':<25} {'çŠ¶æ€':<8} {'èƒœå‡ºæ–¹':<8} {'HPL RMSE':<12} {'L2 RMSE':<12} {'æ”¹è¿›%':<10}")
        print("-" * 80)

        hpl_wins = 0
        l2_wins = 0
        ties = 0

        for dataset_name, result in all_results.items():
            status = "âœ…æˆåŠŸ" if result['status'] == 'success' else "âŒå¤±è´¥"

            if result['status'] == 'success':
                winner = result.get('winner', 'N/A')
                hpl_score = result.get('hpl_score', 'N/A')
                l2_score = result.get('l2_score', 'N/A')
                improvement = result.get('improvement', 0)

                hpl_str = f"{hpl_score:.4f}" if hpl_score != 'N/A' else 'N/A'
                l2_str = f"{l2_score:.4f}" if l2_score != 'N/A' else 'N/A'
                imp_str = f"{improvement:+.2f}" if improvement else '0.00'

                if winner == 'HPL':
                    hpl_wins += 1
                elif winner == 'L2':
                    l2_wins += 1
                else:
                    ties += 1
            else:
                winner = "å¤±è´¥"
                hpl_str = l2_str = imp_str = "N/A"

            print(f"{dataset_name:<25} {status:<8} {winner:<8} {hpl_str:<12} {l2_str:<12} {imp_str:<10}")

        # å¯¹æ¯”æ€»ç»“
        if successful_datasets > 0:
            print(f"\nğŸ† å¯¹æ¯”æ€»ç»“:")
            print(f"   HPLèƒœå‡º: {hpl_wins} æ¬¡")
            print(f"   L2èƒœå‡º: {l2_wins} æ¬¡")
            print(f"   å¹³å±€: {ties} æ¬¡")

            if hpl_wins > l2_wins:
                print(f"   ğŸ‰ HPLæ•´ä½“è¡¨ç°æ›´ä¼˜!")
            elif l2_wins > hpl_wins:
                print(f"   ğŸ“Š L2æ•´ä½“è¡¨ç°æ›´ä¼˜!")
            else:
                print(f"   ğŸ¤ ä¸¤ç§æŸå¤±å‡½æ•°è¡¨ç°ç›¸å½“!")

    # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    summary_data = {
        'experiment_info': {
            'experiment_type': experiment_type,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
            'total_datasets': total_datasets,
            'successful_datasets': successful_datasets,
            'failed_datasets': failed_datasets,
            'total_duration': total_duration
        },
        'detailed_results': all_results
    }

    # ä¿å­˜åˆ° results ç›®å½•
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    results_dir = Path(os.path.join(current_script_dir, 'results'))
    results_dir.mkdir(exist_ok=True)

    summary_filename = f"multi_dataset_summary_{experiment_type}_{time.strftime('%Y%m%d_%H%M%S')}.json"
    summary_path = results_dir / summary_filename

    try:
        # è½¬æ¢numpyç±»å‹
        clean_data = convert_numpy_types(summary_data)

        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(clean_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")
        print(f"ğŸ“ å®Œæ•´è·¯å¾„: {summary_path.absolute()}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜æ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")

    return summary_data


def convert_numpy_types(obj):
    """é€’å½’è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
    if isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif hasattr(obj, 'item'):  # numpy scalar
        return obj.item()
    elif hasattr(obj, 'tolist'):  # numpy array
        return obj.tolist()
    else:
        return obj


def run_multiple_datasets(processed_datasets, experiment_type):
    """é‡æ„åçš„å¤šæ•°æ®é›†æ‰¹é‡å®éªŒå‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸš€ å¼€å§‹æ‰¹é‡æ‰§è¡Œå®éªŒ")
    print("="*80)

    print(f"å°†å¯¹ {len(processed_datasets)} ä¸ªæ•°æ®é›†æ‰§è¡Œ {experiment_type} å®éªŒ")

    all_results = {}

    for i, dataset_info in enumerate(processed_datasets, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ”„ è¿›åº¦: {i}/{len(processed_datasets)}")
        print(f"{'='*60}")

        # æ‰§è¡Œå•ä¸ªæ•°æ®é›†å®éªŒ
        result = execute_single_dataset_experiment(dataset_info, experiment_type)

        # å­˜å‚¨ç»“æœ
        dataset_key = f"{dataset_info['dataset_type']}_{os.path.basename(dataset_info['file_path'])}"
        all_results[dataset_key] = result

        # æ˜¾ç¤ºè¿›åº¦
        if result['status'] == 'success':
            print(f"âœ… å®Œæˆ {i}/{len(processed_datasets)}: {dataset_info['filename']}")
        else:
            print(f"âŒ å¤±è´¥ {i}/{len(processed_datasets)}: {dataset_info['filename']}")

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print("\nğŸ“Š ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
    summary_data = generate_multi_dataset_summary(all_results, experiment_type)

    print(f"\nğŸ‰ å¤šæ•°æ®é›†å®éªŒå®Œæˆ!")
    print(f"   æˆåŠŸ: {len([r for r in all_results.values() if r['status'] == 'success'])}/{len(all_results)}")

    return True


def register_dataset(dataset_name):
    """æ³¨å†ŒæŒ‡å®šçš„æ•°æ®é›†"""
    from data.loader import DatasetLoader
    from data.dataset import MovieLens100K, MovieLens1M, Netflix, AmazonMI, CiaoDVD, Epinions, FilmTrust, MovieTweetings

    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²æ³¨å†Œ
    if dataset_name.lower() in [k.lower() for k in DatasetLoader.DATASET_REGISTRY.keys()]:
        return True

    # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©åˆé€‚çš„ç±»
    if 'filmtrust' in dataset_name.lower() or 'flimtrust' in dataset_name.lower():
        DatasetLoader.register_dataset(dataset_name, FilmTrust)
    elif 'netflix' in dataset_name.lower():
        DatasetLoader.register_dataset(dataset_name, Netflix)
    elif 'amazon' in dataset_name.lower():
        DatasetLoader.register_dataset(dataset_name, AmazonMI)
    elif 'movielens1m' in dataset_name.lower() or 'ml1m' in dataset_name.lower():
        DatasetLoader.register_dataset(dataset_name, MovieLens1M)
    else:
        DatasetLoader.register_dataset(dataset_name, MovieLens100K)

    return True


def main():
    """é‡æ„åçš„ä¸»å‡½æ•° - ç»Ÿä¸€æ‰¹é‡å¤„ç†æ¨¡å¼"""
    try:
        print("HPLæŸå¤±å‡½æ•°ä¼˜åŒ–å®éªŒ - æ‰¹é‡å¤„ç†æ¨¡å¼")
        print("="*60)

        # æ˜¾ç¤ºå½“å‰è„šæœ¬è·¯å¾„å’Œç»“æœä¿å­˜è·¯å¾„
        current_script_dir = os.path.dirname(os.path.abspath(__file__))
        results_save_dir = os.path.join(current_script_dir, 'results')
        print(f"ğŸ“‚ å½“å‰è„šæœ¬ç›®å½•: {current_script_dir}")
        print(f"ğŸ’¾ ç»“æœä¿å­˜ç›®å½•: {results_save_dir}")

        # ç¬¬ä¸€æ­¥ï¼šæ‰«æå¹¶è·å–å¯ç”¨æ•°æ®é›†
        print("\nğŸ“‚ ç¬¬ä¸€æ­¥: æ•°æ®é›†æ‰«æä¸é€‰æ‹©")

        # ä¿®æ”¹ï¼šè·å–æ•°æ®é›†ç›®å½•è·¯å¾„ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œä»é¡¹ç›®æ ¹ç›®å½•è·å–ï¼‰
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        dataset_dir = os.path.join(base_dir, 'dataset')
        print(f"ğŸ” æ•°æ®é›†æœç´¢ç›®å½•: {dataset_dir}")

        # æ‰«æå¯ç”¨æ•°æ®é›†
        dataset_files = scan_available_datasets(dataset_dir)
        if not dataset_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ•°æ®é›†æ–‡ä»¶")
            return False

        # åˆ›å»ºæ•°æ®é›†æ˜ å°„
        dataset_map = create_dataset_mapping(dataset_files)

        # ç”¨æˆ·é€‰æ‹©æ•°æ®é›†
        selected_datasets = get_user_dataset_selection(dataset_map)
        if not selected_datasets:
            print("âŒ æ²¡æœ‰é€‰æ‹©ä»»ä½•æ•°æ®é›†")
            return False

        # ç¬¬äºŒæ­¥ï¼šæ‰¹é‡æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        print("\nğŸ”§ ç¬¬äºŒæ­¥: æ–‡ä»¶æ ¼å¼æ£€æŸ¥ä¸ä¿®å¤")
        processed_datasets = batch_check_file_formats(selected_datasets)

        if not processed_datasets:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®é›†ï¼Œé€€å‡ºå®éªŒ")
            return False

        # ç¬¬ä¸‰æ­¥ï¼šé€‰æ‹©å®éªŒç±»å‹
        print("\nğŸ§ª ç¬¬ä¸‰æ­¥: å®éªŒç±»å‹é€‰æ‹©")
        experiment_type = get_experiment_type_selection()

        # ç¬¬å››æ­¥ï¼šæ‰§è¡Œæ‰¹é‡å®éªŒ
        print("\nğŸƒ ç¬¬å››æ­¥: æ‰¹é‡æ‰§è¡Œå®éªŒ")
        success = run_multiple_datasets(processed_datasets, experiment_type)

        if success:
            print("\nâœ… æ‰€æœ‰å®éªŒå·²å®Œæˆ!")
            send_sms_notification(f"æœ€ä¼˜å‚æ•°å®éªŒå·²å®Œæˆï¼Œæ•°æ®é›†: {', '.join([d.name for d in processed_datasets])}")
        else:
            print("\nâŒ å®éªŒæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜")
            send_sms_notification("æœ€ä¼˜å‚æ•°å®éªŒæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜")

        return success

    except Exception as e:
        print(f"ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        send_sms_notification(f"æœ€ä¼˜å‚æ•°å®éªŒå¤±è´¥: {str(e)[:50]}...")
        return False


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)

