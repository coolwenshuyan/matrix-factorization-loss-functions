## 第 2 步：损失函数模块实现方法详解

### 1. **模块结构设计**

首先创建以下文件结构：

```
src/
├── losses/
│   ├── __init__.py
│   ├── base.py           # 基类定义
│   ├── standard.py       # 标准损失函数（L1, L2）
│   ├── robust.py         # 鲁棒损失函数（Huber, Logcosh）
│   ├── hpl.py            # HPL损失函数
│   ├── siamod.py         # sigmoid损失函数
│   └── utils.py         # 工具函数
```

### 2. **基类设计（base.py）**

#### 抽象基类 `BaseLoss` 设计要点：

**必须实现的方法**：

- `forward(predictions, targets)`: 计算损失值
- `gradient(predictions, targets)`: 计算损失对预测值的梯度
- `get_config()`: 返回损失函数的配置参数
- `__repr__()`: 返回损失函数的字符串表示

**可选方法**：

- `hessian()`: 计算二阶导数（用于牛顿法等优化器）
- `is_differentiable_at()`: 检查在某点是否可导
- `plot()`: 可视化损失函数形状

**设计考虑**：

- 支持批量计算（向量化操作）
- 统一的接口便于模型切换不同损失函数
- 参数验证机制

### 3. **L2 损失函数实现**

**数学定义**：

- 损失: `L(e) = 0.5 * e²`
- 梯度: `∂L/∂e = e`

**实现要点**：

- 最简单的实现，作为基准
- 注意系数 0.5 的使用（使梯度更简洁）
- 无需特殊的数值稳定性处理

### 4. **L1 损失函数实现**

**数学定义**：

- 损失: `L(e) = |e|`
- 梯度: `∂L/∂e = sign(e)`

**实现要点**：

- 在 e=0 处梯度不连续
- 梯度实现时需要处理 e=0 的情况（可以返回 0 或使用次梯度）
- 使用`np.sign()`时注意 0 的处理

### 5. **Huber 损失函数实现**

**数学定义**：

- 当`|e| ≤ δ`时: `L(e) = 0.5 * e²`
- 当`|e| > δ`时: `L(e) = δ * |e| - 0.5 * δ²`

**梯度**：

- 当`|e| ≤ δ`时: `∂L/∂e = e`
- 当`|e| > δ`时: `∂L/∂e = δ * sign(e)`

**实现要点**：

- 需要阈值参数 δ（通常默认为 1.0）
- 确保在`|e| = δ`处连续且可导
- 使用条件判断或`np.where()`实现分段

### 6. **Logcosh 损失函数实现**

**数学定义**：

- 损失: `L(e) = log(cosh(e))`
- 梯度: `∂L/∂e = tanh(e)`

**实现要点**：

- 对大值的数值稳定性处理
- 使用恒等式：`log(cosh(x)) = |x| + log(2) - log(1 + exp(-2|x|))`
- 梯度计算直接使用`tanh()`，但要防止数值溢出

### 7. **HPL 损失函数实现**

**三段式设计**：

#### 第一段（小误差）：`|e| < δ₁`

- 损失: `L(e) = 0.5 * e²`
- 梯度: `∂L/∂e = e`

#### 第二段（中等误差）：`δ₁ ≤ |e| < δ₂`

- 损失: `L(e) = δ₁ * |e| - 0.5 * δ₁²`
- 梯度: `∂L/∂e = δ₁ * sign(e)`

#### 第三段（大误差）：`|e| ≥ δ₂`

- 损失: `L(e) = L_max - (L_max - L_lin(δ₂)) * exp(-B'(|e| - δ₂))`
- 梯度: `∂L/∂e = C_sigmoid * δ₁ * exp(-B'(|e| - δ₂)) * sign(e)`

**C¹ 连续性保证**：

1. **在 δ₁ 处**：

   - 函数值连续：两段在 δ₁ 处的值相等
   - 导数连续：两段在 δ₁ 处的导数都等于 δ₁

2. **在 δ₂ 处**：
   - 函数值连续：通过设计保证
   - 导数连续：通过选择合适的 B'参数实现

**参数计算**：

- `L_lin(δ₂) = δ₁ * δ₂ - 0.5 * δ₁²`
- `B' = C_sigmoid * δ₁ / (L_max - L_lin(δ₂) + ε)`

**实现步骤**：

1. 验证参数约束（δ₁ < δ₂, L_max > L_lin(δ₂)）
2. 预计算常量避免重复计算
3. 使用向量化操作处理批量数据
4. 分别计算三段的掩码（mask）
5. 根据掩码应用对应的公式

### 8. **Sigmoid-like 损失函数实现**

**数学定义**：

- 损失: `L(e) = L_max * (1 - exp(-α * e²))`
- 梯度: `∂L/∂e = 2 * α * L_max * e * exp(-α * e²)`

**实现要点**：

- 参数 α 控制增长速度
- L_max 是损失的上界
- 需要处理大值时的数值稳定性

### 9. **数值稳定性处理**

**常见问题和解决方案**：

1. **除零保护**：

   - 添加小常数 ε（如 1e-8）
   - 在分母为零的地方使用条件判断

2. **指数溢出**：

   - 对指数参数进行裁剪
   - 使用`np.clip()`限制输入范围

3. **对数下溢**：

   - 使用`log1p()`代替`log(1+x)`
   - 添加小常数防止 log(0)

4. **梯度爆炸/消失**：
   - 梯度裁剪
   - 使用稳定的数学等价形式

### 10. **梯度验证实现**

**数值梯度检查**：

- 使用有限差分近似：`(f(x+h) - f(x-h)) / (2h)`
- 选择合适的 h 值（如 1e-5）
- 比较解析梯度和数值梯度的相对误差

**边界情况测试**：

- 在分段点附近密集采样
- 测试极大和极小值
- 验证零点处的行为

### 11. **性能优化**

**向量化计算**：

- 避免 Python 循环，使用 NumPy 向量操作
- 预计算常量
- 使用`np.where()`或布尔索引

**内存效率**：

- 避免创建不必要的中间数组
- 使用 in-place 操作 where 合适
- 考虑使用稀疏表示（如果适用）

### 12. **可视化工具**

**实现损失函数可视化**：

- 绘制损失函数曲线
- 绘制梯度曲线
- 标注关键点（如阈值位置）
- 对比不同损失函数

### 13. **配置管理**

**参数管理**：

- 为每个损失函数定义默认参数
- 支持参数的动态调整
- 参数验证和范围检查
- 序列化和反序列化支持

### 14. **测试策略**

**单元测试**：

- 测试基本功能（forward、gradient）
- 测试特殊值（0、无穷大、NaN）
- 测试批量计算的正确性
- 测试参数验证

**集成测试**：

- 在简单优化问题上测试
- 验证收敛性
- 比较不同损失函数的表现

### 15. **文档和示例**

**文档内容**：

- 数学公式和推导
- 参数说明和建议值
- 使用示例
- 性能特点和适用场景

通过以上详细的实现方法，你将能够构建一个完整、高效、可扩展的损失函数模块，为后续的矩阵分解模型训练提供坚实基础。
