# src/evaluation/ranking.py
import numpy as np
from typing import Dict, List, Optional, Tuple, Set
import heapq
from collections import defaultdict
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

logger = logging.getLogger(__name__)


class TopKGenerator:
    """é«˜æ•ˆçš„Top-Kæ¨èç”Ÿæˆå™¨"""

    def __init__(self, model, use_multithread: bool = True, n_threads: int = 4):
        """
        åˆå§‹åŒ–Top-Kç”Ÿæˆå™¨

        Args:
            model: æ¨èæ¨¡å‹
            use_multithread: æ˜¯å¦ä½¿ç”¨å¤šçº¿ç¨‹
            n_threads: çº¿ç¨‹æ•°
        """
        self.model = model
        self.use_multithread = use_multithread
        self.n_threads = n_threads

    def generate_top_k_for_user(self, user_id: int, k: int = 10,
                               candidate_items: Optional[List[int]] = None,
                               exclude_items: Optional[Set[int]] = None) -> List[int]:
        """
        ä¸ºå•ä¸ªç”¨æˆ·ç”ŸæˆTop-Kæ¨è

        Args:
            user_id: ç”¨æˆ·ID
            k: æ¨èæ•°é‡
            candidate_items: å€™é€‰ç‰©å“åˆ—è¡¨ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰ç‰©å“ï¼‰
            exclude_items: éœ€è¦æ’é™¤çš„ç‰©å“é›†åˆ

        Returns:
            Top-Kç‰©å“IDåˆ—è¡¨
        """
    # ç¡®å®šå€™é€‰ç‰©å“
        if candidate_items is None:
            candidate_items = list(range(self.model.n_items))

        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥æ’é™¤åçš„å€™é€‰ç‰©å“æ•°é‡
        if exclude_items:
            original_count = len(candidate_items)
            candidate_items = [item for item in candidate_items if item not in exclude_items]
            filtered_count = len(candidate_items)

            # å¦‚æœè¿‡æ»¤åå€™é€‰ç‰©å“å¤ªå°‘ï¼Œæ”¾å®½é™åˆ¶
            if filtered_count < k * 2:  # å€™é€‰ç‰©å“å°‘äºkçš„2å€
                print(f"ç”¨æˆ·{user_id}: è¿‡æ»¤åå€™é€‰ç‰©å“ä¸è¶³({filtered_count}), åŸå§‹æ•°é‡({original_count})")
                # æ¢å¤éƒ¨åˆ†å€™é€‰ç‰©å“ï¼Œåªæ’é™¤æœ€è¿‘äº¤äº’çš„ç‰©å“
                if isinstance(exclude_items, set) and len(exclude_items) > k:
                    # åªæ’é™¤æœ€è¿‘çš„kä¸ªç‰©å“ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
                    limited_exclude = set(list(exclude_items)[:k])
                    candidate_items = [item for item in range(self.model.n_items)
                                    if item not in limited_exclude]
                    print(f"é™çº§ç­–ç•¥ï¼šæ’é™¤ç‰©å“æ•°ä»{len(exclude_items)}å‡å°‘åˆ°{len(limited_exclude)}")

        if not candidate_items:
            print(f"âš ï¸ ç”¨æˆ·{user_id}æ²¡æœ‰å¯æ¨èçš„å€™é€‰ç‰©å“")
            return []

        # æ‰¹é‡é¢„æµ‹è¯„åˆ†
        n_candidates = len(candidate_items)
        if n_candidates <= k:
            # å€™é€‰ç‰©å“æ•°é‡å°äºkï¼Œç›´æ¥è¿”å›æ‰€æœ‰
            scores = self.model.predict(
                [user_id] * n_candidates,
                candidate_items
            )
            sorted_indices = np.argsort(scores)[::-1]
            return [candidate_items[i] for i in sorted_indices]

        # ä½¿ç”¨å †ä¼˜åŒ–Top-Ké€‰æ‹©
        if n_candidates > 1000:  # å¤§è§„æ¨¡å€™é€‰é›†
            return self._generate_top_k_with_heap(user_id, candidate_items, k)
        else:  # å°è§„æ¨¡å€™é€‰é›†
            scores = self.model.predict(
                [user_id] * n_candidates,
                candidate_items
            )
            top_k_indices = np.argpartition(scores, -k)[-k:]
            top_k_indices = top_k_indices[np.argsort(scores[top_k_indices])[::-1]]
            return [candidate_items[i] for i in top_k_indices]

    def _generate_top_k_with_heap(self, user_id: int,
                                 candidate_items: List[int],
                                 k: int) -> List[int]:
        """ä½¿ç”¨å †ç»“æ„ç”ŸæˆTop-Kï¼ˆé€‚ç”¨äºå¤§è§„æ¨¡å€™é€‰é›†ï¼‰"""
        # ä½¿ç”¨æœ€å°å †ç»´æŠ¤Top-K
        heap = []
        batch_size = 1000

        for i in range(0, len(candidate_items), batch_size):
            batch_items = candidate_items[i:i + batch_size]
            batch_scores = self.model.predict(
                [user_id] * len(batch_items),
                batch_items
            )

            for item, score in zip(batch_items, batch_scores):
                if len(heap) < k:
                    heapq.heappush(heap, (score, item))
                elif score > heap[0][0]:
                    heapq.heapreplace(heap, (score, item))

        # æŒ‰åˆ†æ•°é™åºæ’åº
        top_k = sorted(heap, key=lambda x: x[0], reverse=True)
        return [item for score, item in top_k]

    def generate_top_k_for_users(self, user_ids: List[int], k: int = 10,
                                exclude_known: bool = True,
                                known_items: Optional[Dict[int, List[int]]] = None,
                                show_progress: bool = True) -> Dict[int, List[int]]:
        """
        ä¸ºå¤šä¸ªç”¨æˆ·ç”ŸæˆTop-Kæ¨è

        Args:
            user_ids: ç”¨æˆ·IDåˆ—è¡¨
            k: æ¨èæ•°é‡
            exclude_known: æ˜¯å¦æ’é™¤å·²çŸ¥ç‰©å“
            known_items: ç”¨æˆ·å·²çŸ¥ç‰©å“å­—å…¸
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡

        Returns:
            ç”¨æˆ·IDåˆ°æ¨èåˆ—è¡¨çš„å­—å…¸
        """
        recommendations = {}

        if self.use_multithread and len(user_ids) > 10:
            # å¤šçº¿ç¨‹å¤„ç†
            with ThreadPoolExecutor(max_workers=self.n_threads) as executor:
                # æäº¤ä»»åŠ¡
                future_to_user = {}
                for user_id in user_ids:
                    exclude_items = None
                    if exclude_known and known_items and user_id in known_items:
                        exclude_items = set(known_items[user_id])

                    future = executor.submit(
                        self.generate_top_k_for_user,
                        user_id, k, None, exclude_items
                    )
                    future_to_user[future] = user_id

                # æ”¶é›†ç»“æœ
                if show_progress:
                    pbar = tqdm(total=len(user_ids), desc="ç”Ÿæˆæ¨è")

                for future in as_completed(future_to_user):
                    user_id = future_to_user[future]
                    try:
                        rec_items = future.result()
                        recommendations[user_id] = rec_items
                    except Exception as e:
                        logger.error(f"ä¸ºç”¨æˆ· {user_id} ç”Ÿæˆæ¨èæ—¶å‡ºé”™: {str(e)}")
                        recommendations[user_id] = []

                    if show_progress:
                        pbar.update(1)

                if show_progress:
                    pbar.close()
        else:
            # å•çº¿ç¨‹å¤„ç†
            if show_progress:
                user_ids = tqdm(user_ids, desc="ç”Ÿæˆæ¨è")

            for user_id in user_ids:
                exclude_items = None
                if exclude_known and known_items and user_id in known_items:
                    exclude_items = set(known_items[user_id])

                rec_items = self.generate_top_k_for_user(
                    user_id, k, None, exclude_items
                )
                recommendations[user_id] = rec_items

        return recommendations


class RankingEvaluator:
    """æ’åºè¯„ä¼°å™¨"""

    def __init__(self, model, k_values: List[int] = [5, 10, 20]):
        """
        åˆå§‹åŒ–æ’åºè¯„ä¼°å™¨

        Args:
            model: æ¨èæ¨¡å‹
            k_values: è¯„ä¼°çš„Kå€¼åˆ—è¡¨
        """
        self.model = model
        self.k_values = k_values
        self.topk_generator = TopKGenerator(model)

    def evaluate_user_ranking(self, user_id: int, true_items: List[int],
                            k: int = 10,
                            candidate_items: Optional[List[int]] = None) -> Dict[str, float]:
        """
        è¯„ä¼°å•ä¸ªç”¨æˆ·çš„æ’åºè´¨é‡

        Args:
            user_id: ç”¨æˆ·ID
            true_items: çœŸå®ç›¸å…³ç‰©å“åˆ—è¡¨
            k: Top-Kå€¼
            candidate_items: å€™é€‰ç‰©å“åˆ—è¡¨

        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        # ç”Ÿæˆæ¨è
        rec_items = self.topk_generator.generate_top_k_for_user(
            user_id, k, candidate_items
        )

        if not rec_items or not true_items:
            return {
                'precision': 0.0,
                'recall': 0.0,
                'f1': 0.0,
                'hit': 0.0
            }

        # è®¡ç®—æŒ‡æ ‡
        rec_set = set(rec_items)
        true_set = set(true_items)
        n_relevant = len(rec_set & true_set)

        precision = n_relevant / len(rec_items)
        recall = n_relevant / len(true_items)
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        hit = 1.0 if n_relevant > 0 else 0.0

        return {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'hit': hit
        }

    def evaluate_ranking_efficiency(self, n_users: int = 100,
                                  k: int = 10) -> Dict[str, float]:
        """
        è¯„ä¼°æ’åºæ•ˆç‡

        Args:
            n_users: æµ‹è¯•ç”¨æˆ·æ•°
            k: Top-Kå€¼

        Returns:
            æ•ˆç‡æŒ‡æ ‡
        """
        import time

        # éšæœºé€‰æ‹©ç”¨æˆ·
        test_users = np.random.choice(self.model.n_users, n_users, replace=False)

        # æµ‹è¯•å•çº¿ç¨‹æ€§èƒ½
        start_time = time.time()
        single_thread_gen = TopKGenerator(self.model, use_multithread=False)
        single_thread_gen.generate_top_k_for_users(test_users.tolist(), k, show_progress=False)
        single_thread_time = time.time() - start_time

        # æµ‹è¯•å¤šçº¿ç¨‹æ€§èƒ½
        start_time = time.time()
        multi_thread_gen = TopKGenerator(self.model, use_multithread=True, n_threads=4)
        multi_thread_gen.generate_top_k_for_users(test_users.tolist(), k, show_progress=False)
        multi_thread_time = time.time() - start_time

        return {
            'single_thread_time': single_thread_time,
            'multi_thread_time': multi_thread_time,
            'speedup': single_thread_time / multi_thread_time,
            'users_per_second_single': n_users / single_thread_time,
            'users_per_second_multi': n_users / multi_thread_time
        }


class DiversityOptimizer:
    """å¤šæ ·æ€§ä¼˜åŒ–å™¨"""

    def __init__(self, item_features: Optional[np.ndarray] = None,
                 similarity_threshold: float = 0.5):
        """
        åˆå§‹åŒ–å¤šæ ·æ€§ä¼˜åŒ–å™¨
        Args:
           item_features: ç‰©å“ç‰¹å¾çŸ©é˜µ
           similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
       """
        self.item_features = item_features
        self.similarity_threshold = similarity_threshold

        # é¢„è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦ï¼ˆå¦‚æœæä¾›äº†ç‰¹å¾ï¼‰
        if item_features is not None:
            self._precompute_similarities()

    def _precompute_similarities(self):
        """é¢„è®¡ç®—ç‰©å“é—´çš„ç›¸ä¼¼åº¦"""
        # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
        norms = np.linalg.norm(self.item_features, axis=1)
        self.item_features_normalized = self.item_features / (norms[:, np.newaxis] + 1e-8)

        # ä¸ºäº†å†…å­˜æ•ˆç‡ï¼Œä¸é¢„è®¡ç®—å®Œæ•´çš„ç›¸ä¼¼åº¦çŸ©é˜µ
        # è€Œæ˜¯åœ¨éœ€è¦æ—¶åŠ¨æ€è®¡ç®—

    def diversify_recommendations(self, original_recs: List[int],
                                scores: List[float],
                                k: int,
                                lambda_diversity: float = 0.5) -> List[int]:
        """
        ä½¿ç”¨MMRï¼ˆMaximal Marginal Relevanceï¼‰ç®—æ³•å¢åŠ æ¨èå¤šæ ·æ€§

        Args:
            original_recs: åŸå§‹æ¨èåˆ—è¡¨
            scores: å¯¹åº”çš„åˆ†æ•°
            k: æœ€ç»ˆæ¨èæ•°é‡
            lambda_diversity: å¤šæ ·æ€§æƒé‡ï¼ˆ0-1ä¹‹é—´ï¼‰

        Returns:
            å¤šæ ·åŒ–åçš„æ¨èåˆ—è¡¨
        """
        if self.item_features is None or len(original_recs) <= k:
            return original_recs[:k]

        # å½’ä¸€åŒ–åˆ†æ•°
        scores = np.array(scores)
        if np.max(scores) > np.min(scores):
            scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))

        # MMRç®—æ³•
        selected = []
        candidates = list(zip(original_recs, scores))

        # é€‰æ‹©ç¬¬ä¸€ä¸ªç‰©å“ï¼ˆæœ€é«˜åˆ†ï¼‰
        first_item = max(candidates, key=lambda x: x[1])
        selected.append(first_item[0])
        candidates.remove(first_item)

        # è¿­ä»£é€‰æ‹©å‰©ä½™ç‰©å“
        while len(selected) < k and candidates:
            mmr_scores = []

            for item, score in candidates:
                # ç›¸å…³æ€§åˆ†æ•°
                relevance = score

                # å¤šæ ·æ€§åˆ†æ•°ï¼ˆä¸å·²é€‰æ‹©ç‰©å“çš„æœ€å¤§ç›¸ä¼¼åº¦ï¼‰
                max_sim = 0
                for selected_item in selected:
                    sim = self._compute_similarity(item, selected_item)
                    max_sim = max(max_sim, sim)

                # MMRåˆ†æ•°
                mmr = lambda_diversity * relevance - (1 - lambda_diversity) * max_sim
                mmr_scores.append((item, mmr))

            # é€‰æ‹©MMRåˆ†æ•°æœ€é«˜çš„ç‰©å“
            best_item = max(mmr_scores, key=lambda x: x[1])[0]
            selected.append(best_item)

            # ä»å€™é€‰ä¸­ç§»é™¤
            candidates = [(item, score) for item, score in candidates if item != best_item]

        return selected

    def _compute_similarity(self, item1: int, item2: int) -> float:
        """è®¡ç®—ä¸¤ä¸ªç‰©å“çš„ç›¸ä¼¼åº¦"""
        if self.item_features is None:
            return 0.0

        if item1 >= len(self.item_features) or item2 >= len(self.item_features):
            return 0.0

        # ä½™å¼¦ç›¸ä¼¼åº¦
        feat1 = self.item_features_normalized[item1]
        feat2 = self.item_features_normalized[item2]

        return float(np.dot(feat1, feat2))
