#!/usr/bin/env python3
"""
å¿«é€Ÿé…ç½®MAEä¼˜åŒ–ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•åœ¨ç°æœ‰æ¡†æ¶ä¸­å¿«é€Ÿé…ç½®MAEä½œä¸ºä¼˜åŒ–ç›®æ ‡çš„ç®€å•ç¤ºä¾‹
"""

import sys
import os
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from data.data_manager import DataManager
from src.models.mf_sgd import MatrixFactorizationSGD
from src.models.initializers import NormalInitializer
from src.models.regularizers import L2Regularizer
from src.losses.hpl import HybridPiecewiseLoss
from src.losses.standard import L2Loss, L1Loss
from src.evaluation.metrics import MAE, RMSE


def quick_mae_example():
    """å¿«é€ŸMAEé…ç½®ç¤ºä¾‹"""
    print("å¿«é€ŸMAEé…ç½®ç¤ºä¾‹")
    print("="*50)
    
    # 1. æ•°æ®å‡†å¤‡
    print("1. å‡†å¤‡æ•°æ®...")
    data_config = {
        'random_seed': 42,
        'train_ratio': 0.8,
        'val_ratio': 0.1,
        'test_ratio': 0.1,
        'center_data': True
    }
    
    data_manager = DataManager(data_config)
    data_manager.load_dataset('movielens100k', 'dataset/20201202M100K_data_all_random.txt')
    data_manager.preprocess()
    
    train_data, val_data, test_data = data_manager.get_splits()
    stats = data_manager.get_statistics()
    
    print(f"æ•°æ®ç»Ÿè®¡: {stats['n_users']} ç”¨æˆ·, {stats['n_items']} ç‰©å“")
    print(f"è®­ç»ƒé›†: {len(train_data)} æ¡")
    
    # 2. åˆå§‹åŒ–è¯„ä¼°æŒ‡æ ‡
    mae_metric = MAE()
    rmse_metric = RMSE()
    
    # 3. å®šä¹‰ä¸‰ç§æŸå¤±å‡½æ•°é…ç½®
    loss_configs = {
        'HPL': {
            'loss': HybridPiecewiseLoss(delta1=0.5, delta2=1.5, l_max=4.0, c_sigmoid=1.0),
            'name': 'HPLæ··åˆåˆ†æ®µæŸå¤±'
        },
        'L2': {
            'loss': L2Loss(),
            'name': 'L2æŸå¤±(MSE)'
        },
        'L1': {
            'loss': L1Loss(epsilon=1e-8),
            'name': 'L1æŸå¤±(MAE)'
        }
    }
    
    # 4. æµ‹è¯•æ¯ç§æŸå¤±å‡½æ•°åœ¨MAEæŒ‡æ ‡ä¸Šçš„è¡¨ç°
    results = {}
    
    for loss_name, loss_config in loss_configs.items():
        print(f"\n2. æµ‹è¯• {loss_config['name']}...")
        
        # ğŸ¯ å…³é”®é…ç½®ï¼šåˆ›å»ºæ¨¡å‹æ—¶æŒ‡å®šæŸå¤±å‡½æ•°
        model = MatrixFactorizationSGD(
            n_users=stats['n_users'],
            n_items=stats['n_items'],
            n_factors=50,                    # æ½œåœ¨å› å­æ•°
            learning_rate=0.02,             # å­¦ä¹ ç‡
            regularizer=L2Regularizer(lambda_reg=0.01),  # æ­£åˆ™åŒ–
            loss_function=loss_config['loss'],           # ğŸ¯ æŒ‡å®šæŸå¤±å‡½æ•°
            use_bias=True,
            global_mean=data_manager.global_mean or 0.0
        )
        
        # åˆå§‹åŒ–å‚æ•°
        initializer = NormalInitializer(mean=0.0, std=0.01)
        model.initialize_parameters(initializer)
        
        # è®­ç»ƒæ¨¡å‹
        print(f"   è®­ç»ƒ {loss_name} æ¨¡å‹...")
        model.fit(
            train_data=train_data,
            val_data=val_data,
            n_epochs=30,                    # è®­ç»ƒè½®æ•°
            verbose=0                       # ä¸æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹
        )
        
        # ğŸ¯ å…³é”®è¯„ä¼°ï¼šåœ¨éªŒè¯é›†ä¸Šè®¡ç®—MAEå’ŒRMSE
        val_predictions = model.predict(
            val_data[:, 0].astype(int),
            val_data[:, 1].astype(int)
        )
        
        # è¿˜åŸæ•°æ®å°ºåº¦
        if data_manager.global_mean is not None:
            val_predictions += data_manager.global_mean
            val_targets = val_data[:, 2] + data_manager.global_mean
        else:
            val_targets = val_data[:, 2]
        
        # ğŸ¯ è®¡ç®—MAEå’ŒRMSEæŒ‡æ ‡
        mae_score = mae_metric.calculate(val_targets, val_predictions)
        rmse_score = rmse_metric.calculate(val_targets, val_predictions)
        
        results[loss_name] = {
            'mae': mae_score,
            'rmse': rmse_score,
            'name': loss_config['name']
        }
        
        print(f"   {loss_name} ç»“æœ: MAE={mae_score:.4f}, RMSE={rmse_score:.4f}")
    
    # 5. ğŸ¯ å…³é”®ç»“æœï¼šMAEæŒ‡æ ‡å¯¹æ¯”
    print("\n" + "="*50)
    print("MAEæŒ‡æ ‡å¯¹æ¯”ç»“æœ")
    print("="*50)
    
    print(f"{'æŸå¤±å‡½æ•°':<15} {'MAE':<10} {'RMSE':<10} {'MAEæ’å':<10}")
    print("-" * 50)
    
    # æŒ‰MAEæ’åº
    sorted_results = sorted(results.items(), key=lambda x: x[1]['mae'])
    
    for rank, (loss_name, result) in enumerate(sorted_results, 1):
        print(f"{result['name']:<15} {result['mae']:<10.4f} {result['rmse']:<10.4f} {rank:<10}")
    
    # 6. åˆ†æå’Œå»ºè®®
    print(f"\nåˆ†æ:")
    best_loss, best_result = sorted_results[0]
    print(f"âœ… {best_result['name']} åœ¨MAEæŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³: {best_result['mae']:.4f}")
    
    if best_loss == 'L1':
        print("ğŸ¯ ç¬¦åˆé¢„æœŸï¼šL1æŸå¤±ç›´æ¥ä¼˜åŒ–MAEï¼Œç†è®ºä¸Šåº”è¯¥æœ€ä¼˜")
    elif best_loss == 'HPL':
        print("ğŸ‰ HPLæŸå¤±åœ¨MAEä¸Šè¶…è¶Šäº†L1ï¼åˆ†æ®µç­–ç•¥ç¡®å®æœ‰æ•ˆ")
    else:
        print("ğŸ“Š L2æŸå¤±æ„å¤–è¡¨ç°æœ€ä½³ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å…¶ä»–å‚æ•°")
    
    print(f"\nğŸ’¡ é…ç½®å»ºè®®:")
    print(f"å¦‚æœè¦ä¼˜åŒ–MAEæŒ‡æ ‡ï¼Œæ¨èé…ç½®:")
    print(f"1. æŸå¤±å‡½æ•°: {best_result['name']}")
    print(f"2. è¯„ä¼°æŒ‡æ ‡: MAE")
    print(f"3. å‚æ•°è°ƒæ•´: å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–å­¦ä¹ ç‡ã€æ­£åˆ™åŒ–ç­‰")
    
    return results


def show_mae_configuration_guide():
    """å±•ç¤ºMAEé…ç½®æŒ‡å—"""
    print("\n" + "="*60)
    print("MAEé…ç½®å®Œæ•´æŒ‡å—")
    print("="*60)
    
    guide = """
ğŸ“‹ å¦‚ä½•é…ç½®MAEä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼š

1ï¸âƒ£ å¯¼å…¥MAEè¯„ä¼°æŒ‡æ ‡ï¼š
   from src.evaluation.metrics import MAE
   mae_metric = MAE()

2ï¸âƒ£ é€‰æ‹©é€‚åˆMAEçš„æŸå¤±å‡½æ•°ï¼š
   æ–¹æ¡ˆAï¼šç›´æ¥ä½¿ç”¨L1æŸå¤±ï¼ˆç†è®ºæœ€ä¼˜ï¼‰
   from src.losses.standard import L1Loss
   loss_function = L1Loss(epsilon=1e-8)
   
   æ–¹æ¡ˆBï¼šä½¿ç”¨HPLæŸå¤±ï¼ˆå¯èƒ½æ›´ä¼˜ï¼‰
   from src.losses.hpl import HybridPiecewiseLoss
   loss_function = HybridPiecewiseLoss(delta1=0.5, delta2=1.5)
   
   æ–¹æ¡ˆCï¼šä½¿ç”¨L2æŸå¤±ï¼ˆä½œä¸ºåŸºçº¿ï¼‰
   from src.losses.standard import L2Loss
   loss_function = L2Loss()

3ï¸âƒ£ åˆ›å»ºç›®æ ‡å‡½æ•°ä¼˜åŒ–MAEï¼š
   def objective_function(config):
       # åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨é€‰å®šçš„æŸå¤±å‡½æ•°ï¼‰
       model = MatrixFactorizationSGD(
           n_users=n_users,
           n_items=n_items,
           n_factors=config['factors'],
           learning_rate=config['lr'],
           loss_function=loss_function,  # ğŸ¯ å…³é”®ï¼šæŒ‡å®šæŸå¤±å‡½æ•°
           ...
       )
       
       # è®­ç»ƒæ¨¡å‹
       model.fit(train_data, val_data, ...)
       
       # ğŸ¯ å…³é”®ï¼šè¯„ä¼°MAE
       predictions = model.predict(...)
       mae = mae_metric.calculate(targets, predictions)
       return mae  # è¿”å›MAEä½œä¸ºä¼˜åŒ–ç›®æ ‡

4ï¸âƒ£ é…ç½®è¶…å‚æ•°ä¼˜åŒ–ï¼š
   optimizer = HyperOptimizer(
       objective_fn=objective_function,
       maximize=False,  # ğŸ¯ å…³é”®ï¼šæœ€å°åŒ–MAE
       ...
   )

5ï¸âƒ£ è¿è¡Œä¼˜åŒ–å¹¶åˆ†æç»“æœï¼š
   best_trial = optimizer.optimize(n_trials=50)
   print(f"æœ€ä½³MAE: {best_trial.score}")

ğŸ’¡ é‡è¦æç¤ºï¼š
- L1æŸå¤±ç†è®ºä¸Šæœ€é€‚åˆMAEä¼˜åŒ–
- HPLæŸå¤±å¯èƒ½é€šè¿‡åˆ†æ®µç­–ç•¥è·å¾—æ›´å¥½æ•ˆæœ
- è®°å¾—è®¾ç½®maximize=Falseæ¥æœ€å°åŒ–MAE
- å¯ä»¥åŒæ—¶ç›‘æ§RMSEæ¥å…¨é¢è¯„ä¼°
"""
    
    print(guide)


if __name__ == '__main__':
    print("MAEé…ç½®ç¤ºä¾‹å’ŒæŒ‡å—")
    print("="*60)
    
    # è¿è¡Œå¿«é€Ÿç¤ºä¾‹
    results = quick_mae_example()
    
    # æ˜¾ç¤ºé…ç½®æŒ‡å—
    show_mae_configuration_guide()
    
    print("\nâœ… ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("ğŸ’¡ å‚è€ƒä¸Šé¢çš„é…ç½®æŒ‡å—æ¥è®¾ç½®æ‚¨è‡ªå·±çš„MAEä¼˜åŒ–å®éªŒ")
